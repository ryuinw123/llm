{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea9943a-1096-46e6-be70-9ad022488c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dace4e5-d8fa-4ac4-9154-77784a4760f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15934440-fbe7-4504-ae10-a581efc8b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset name\n",
    "dataset_name = \"code_search_net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9270406-52ac-4c2e-864a-13ee70b66767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryu\\.conda\\envs\\llm\\Lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(dataset_name, \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bbf7527-ab67-4530-99b5-564c14eba3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def last_rate_limit(self):\n",
      "        \"\"\"\n",
      "        A `dict` of the rate limit information returned in the most recent\n",
      "        response, or `None` if no requests have been made yet.  The `dict`\n",
      "        consists of all headers whose names begin with ``\"RateLimit\"`` (case\n",
      "        insensitive).\n",
      "\n",
      "        The DigitalOcean API specifies the following rate limit headers:\n",
      "\n",
      "        :var string RateLimit-Limit: the number of requests that can be made\n",
      "            per hour\n",
      "        :var string RateLimit-Remaining: the number of requests remaining until\n",
      "            the limit is reached\n",
      "        :var string RateLimit-Reset: the Unix timestamp for the time when the\n",
      "            oldest request will expire from rate limit consideration\n",
      "        \"\"\"\n",
      "        if self.last_response is None:\n",
      "            return None\n",
      "        else:\n",
      "            return {k:v for k,v in iteritems(self.last_response.headers)\n",
      "                        if k.lower().startswith('ratelimit')}\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][123456][\"whole_func_string\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98ce99-704b-469f-b490-04abe3bfc7c7",
   "metadata": {},
   "source": [
    "### Train/Eval Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5492465c-c1b8-4f04-a154-36ce3bcb6610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = raw_datasets[\"train\"]\n",
    "eval_dataset = raw_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d83300-c256-47be-9e13-814522c12d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412178"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc4a5b43-826b-4cb3-bed5-5c8654400398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_dataset = [\n",
    "#    {key: eval_dataset[key][idx] for key in eval_dataset}\n",
    "#    for idx in range(len(eval_dataset))\n",
    "#]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc9e43-55b5-4a7b-902f-b8a3b82dbf06",
   "metadata": {},
   "source": [
    "We should save the split to W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6f6a55-fd66-4215-bee7-1a05ef91e037",
   "metadata": {},
   "source": [
    "Some other instruction have some context in the `input` variable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b795343f-0356-4689-8bc6-9ac650716c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_alpaca_prompt(row):\n",
    "    return (\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{func_documentation_string}\\n\\n### Input\\nถ้าเป็นเขียนโค้ด ให้ใช้ภาษา {language}\\n\\n### Response:\\n\"\"\").format_map(row)\n",
    "def create_wangchai_prompt(row):\n",
    "    return (\"\"\"<context>: {func_documentation_string} <human>: เขียนโค้ดโดยใช้ภาษา Python <bot>:\"\"\").format_map(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04d0035e-96e6-4d69-ba1f-06e0051a3db6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<context>: Returns the schema of this :class:`DataFrame` as a :class:`pyspark.sql.types.StructType`.\n",
      "\n",
      "        >>> df.schema\n",
      "        StructType(List(StructField(age,IntegerType,true),StructField(name,StringType,true))) <human>: เขียนโค้ดโดยใช้ภาษา Python <bot>:\n"
     ]
    }
   ],
   "source": [
    "row = train_dataset[232]\n",
    "print(create_wangchai_prompt(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f74b3e-8ca2-4c57-b37f-225164c2cb5a",
   "metadata": {},
   "source": [
    "> But you are leaving the output out!!! Yes, but we can just concat that afterwards. Let's deal with the prompt now, we can add the output later with the right amount of padding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee98efa-c7ed-43a9-94bc-aad7e0da735f",
   "metadata": {},
   "source": [
    "And the refactored function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c34cc42-c38c-4e6f-bfb6-0f32d48aef5d",
   "metadata": {},
   "source": [
    "## Why are we doing all this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0cbc7-7d45-45b4-8e32-f3153b0d9ce2",
   "metadata": {},
   "source": [
    "Let's load back the artifact we uploaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31dd88-e90e-4697-b354-b39eed0fab3c",
   "metadata": {},
   "source": [
    "Because we need to tokenize this dataset in a very particular way, if we want the model to learn to predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41703ce9-a22d-4245-9f6c-a424afd9ef11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_prompts = [create_wangchai_prompt(row) for row in train_dataset]\n",
    "eval_prompts = [create_wangchai_prompt(row) for row in eval_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a4c16a0-989b-4e17-bc07-e1cc95971813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<context>: Trains a k-nearest neighbors classifier for face recognition.\n",
      "\n",
      "    :param train_dir: directory that contains a sub-directory for each known person, with its name.\n",
      "\n",
      "     (View in source code to see train_dir example tree structure)\n",
      "\n",
      "     Structure:\n",
      "        <train_dir>/\n",
      "        ├── <person1>/\n",
      "        │   ├── <somename1>.jpeg\n",
      "        │   ├── <somename2>.jpeg\n",
      "        │   ├── ...\n",
      "        ├── <person2>/\n",
      "        │   ├── <somename1>.jpeg\n",
      "        │   └── <somename2>.jpeg\n",
      "        └── ...\n",
      "\n",
      "    :param model_save_path: (optional) path to save model on disk\n",
      "    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\n",
      "    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\n",
      "    :param verbose: verbosity of training\n",
      "    :return: returns knn classifier that was trained on the given data. <human>: เขียนโค้ดโดยใช้ภาษา Python <bot>:\n"
     ]
    }
   ],
   "source": [
    "print(train_prompts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69153b-eb20-4f6d-afba-5b737d36320b",
   "metadata": {},
   "source": [
    "We need to process the targets and add the End Of String token (EOS) to the results. For LLama this is: `\"</s>\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06177a5c-84ff-4be3-8d2b-6a483c8ae5e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_eos(ds):\n",
    "    EOS_TOKEN = \"</s>\"\n",
    "    return [f\"{row['func_code_string']}{EOS_TOKEN}\" for row in ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5b21e8-3d5b-4964-be7b-faff5038f7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \"\"\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \"\"\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf</s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outputs = pad_eos(train_dataset)\n",
    "eval_outputs = pad_eos(eval_dataset)\n",
    "train_outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42190f2-20cf-4960-866b-ccb7700b5b20",
   "metadata": {},
   "source": [
    "Cool! but why we have everything separated? Let's sore the \"final\" version on a variable called `examples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdea7bc4-1ec3-451e-ab00-549aa2056800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = [{\"prompt\":s, \"output\":t, \"example\": s + t} for s, t in zip(train_prompts, train_outputs)]\n",
    "eval_dataset = [{\"prompt\":s, \"output\":t, \"example\": s + t} for s, t in zip(eval_prompts, eval_outputs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad92d95-23d5-474c-9271-59948d5dcbb0",
   "metadata": {},
   "source": [
    "This is what the model need to see and learn =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e923b9bb-ced2-44f9-88f3-1c7690dde802",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<context>: Shows the face recognition results visually.\n",
      "\n",
      "    :param img_path: path to image to be recognized\n",
      "    :param predictions: results of the predict function\n",
      "    :return: <human>: เขียนโค้ดโดยใช้ภาษา Python <bot>:\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[2][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcc001d6-1666-40ec-8b5b-cd977f864ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def show_prediction_labels_on_image(img_path, predictions):\n",
      "    \"\"\"\n",
      "    Shows the face recognition results visually.\n",
      "\n",
      "    :param img_path: path to image to be recognized\n",
      "    :param predictions: results of the predict function\n",
      "    :return:\n",
      "    \"\"\"\n",
      "    pil_image = Image.open(img_path).convert(\"RGB\")\n",
      "    draw = ImageDraw.Draw(pil_image)\n",
      "\n",
      "    for name, (top, right, bottom, left) in predictions:\n",
      "        # Draw a box around the face using the Pillow module\n",
      "        draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
      "\n",
      "        # There's a bug in Pillow where it blows up with non-UTF-8 text\n",
      "        # when using the default bitmap font\n",
      "        name = name.encode(\"UTF-8\")\n",
      "\n",
      "        # Draw a label with a name below the face\n",
      "        text_width, text_height = draw.textsize(name)\n",
      "        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
      "        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
      "\n",
      "    # Remove the drawing library from memory as per the Pillow docs\n",
      "    del draw\n",
      "\n",
      "    # Display the resulting image\n",
      "    pil_image.show()</s>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[2][\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f7474dd-c6b6-4a3e-a4c1-53a111194a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<context>: Shows the face recognition results visually.\n",
      "\n",
      "    :param img_path: path to image to be recognized\n",
      "    :param predictions: results of the predict function\n",
      "    :return: <human>: เขียนโค้ดโดยใช้ภาษา Python <bot>:def show_prediction_labels_on_image(img_path, predictions):\n",
      "    \"\"\"\n",
      "    Shows the face recognition results visually.\n",
      "\n",
      "    :param img_path: path to image to be recognized\n",
      "    :param predictions: results of the predict function\n",
      "    :return:\n",
      "    \"\"\"\n",
      "    pil_image = Image.open(img_path).convert(\"RGB\")\n",
      "    draw = ImageDraw.Draw(pil_image)\n",
      "\n",
      "    for name, (top, right, bottom, left) in predictions:\n",
      "        # Draw a box around the face using the Pillow module\n",
      "        draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
      "\n",
      "        # There's a bug in Pillow where it blows up with non-UTF-8 text\n",
      "        # when using the default bitmap font\n",
      "        name = name.encode(\"UTF-8\")\n",
      "\n",
      "        # Draw a label with a name below the face\n",
      "        text_width, text_height = draw.textsize(name)\n",
      "        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
      "        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
      "\n",
      "    # Remove the drawing library from memory as per the Pillow docs\n",
      "    del draw\n",
      "\n",
      "    # Display the resulting image\n",
      "    pil_image.show()</s>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[2][\"example\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e10a73bd-51be-4c3c-a011-dc81cf448dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_length = 768\n",
    "train_dataset = [data for data in train_dataset if len(data[\"example\"]) <= tokenizer_length][:25000]\n",
    "eval_dataset = [data for data in eval_dataset if len(data[\"example\"]) <= tokenizer_length][:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d45c478-9a05-4abb-9464-c1a120661cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5270873e-53d4-492b-bdce-b4d8ed8084bd",
   "metadata": {},
   "source": [
    "## Converting text to numbers: Tokenizer\n",
    "We need to convert the dataset into tokens, you can quickly do this with the workhorse of the transformers library, the Tokenizer! This function does a lot of heavy lifting besides tokenizing the text. \n",
    "\n",
    "- It tokenizes the text\n",
    "- Converts the outputs to PyTorch tensors\n",
    "- Pads the inputs to match length and more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "720c707b-3bce-4164-b8c1-3c3122200c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4162aec8-f2ba-45db-9633-817b416d4e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_path = r'C:\\Users\\ryu\\Desktop\\llm\\finetune-wangchai-11212023\\base_model'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8926d179-dba3-469d-93b4-d393a113ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_data = [data[\"example\"] for data in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2802028-7b51-4802-80bd-d18efcb965f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<context>: Convert a dlib \\'rect\\' object to a plain tuple in (top, right, bottom, left) order\\n\\n    :param rect: a dlib \\'rect\\' object\\n    :return: a plain tuple representation of the rect in (top, right, bottom, left) order <human>: เขียนโค้ดโดยใช้ภาษา Python <bot>:def _rect_to_css(rect):\\n    \"\"\"\\n    Convert a dlib \\'rect\\' object to a plain tuple in (top, right, bottom, left) order\\n\\n    :param rect: a dlib \\'rect\\' object\\n    :return: a plain tuple representation of the rect in (top, right, bottom, left) order\\n    \"\"\"\\n    return rect.top(), rect.right(), rect.bottom(), rect.left()</s>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b6e9997-764d-4cdf-b3a2-6695988740cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len tokenizer before train 256008\n",
      "len tokenizer after train 256008\n"
     ]
    }
   ],
   "source": [
    "print(\"len tokenizer before train\" , len(tokenizer))\n",
    "#tokenizer = tokenizer.train_new_from_iterator(tokenizer_data, len(tokenizer))\n",
    "print(\"len tokenizer after train\" , len(tokenizer))\n",
    "#tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "337fedfd-e238-4e86-a96b-24dfeed11f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1622, 19138, 7, 256, 3168, 19937, 35]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"My experiments are going strong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20c69466-f7e6-45b8-a167-718c80cedc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1622, 19138, 7, 256, 3168, 19937, 35, 2, 2]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"My experiments are going strong!\", padding='max_length', max_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb1e5e29-254a-4dbf-ac02-ea6bb2a16e77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,  1622, 19138,     7,   256,  3168, 19937,    35,     2,     2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"My experiments are going strong!\", \n",
    "                 padding='max_length', \n",
    "                 max_length=10,\n",
    "                 return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02f74059-48fa-4056-8b77-baa2b64a0df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,    44,  2240, 97067,  2597,     2,     2,     2,     2,     2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"I love Llamas\", \n",
    "                 padding='max_length', \n",
    "                 max_length=10,\n",
    "                 return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a89a61d-34b7-4a56-b1d8-98ebcf3384d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,  1622, 19138,     7,   256,  3168, 19937,    35,     2,     2],\n",
       "        [    2,    44,  2240, 97067,  2597,     2,     2,     2,     2,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"My experiments are going strong!\", \n",
    "           \"I love Llamas\"], \n",
    "          padding='max_length', \n",
    "          # padding='longest',\n",
    "          max_length=10,\n",
    "          return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83a02b1a-4b31-4402-8426-0353caa878ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "733b657d-446b-404c-af74-2e50dce5244a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c0257e5-37bb-4eec-905c-983ec25d25ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkds_ids = tokenizer([s[\"example\"] for s in train_dataset])[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58586813-7918-4578-9583-df14c5a6a6ad",
   "metadata": {},
   "source": [
    "### Packing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316d169-4292-41aa-a42d-cd49620a881c",
   "metadata": {},
   "source": [
    "We will pack multiple short examples into a longer chunk, so we can train more efficiently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a537da60-db69-42a7-8c66-0ea3756c2847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sequence_len = 512\n",
    "\n",
    "def pack(dataset, max_seq_len=max_sequence_len):\n",
    "    tkds_ids = tokenizer([s[\"example\"] for s in dataset])[\"input_ids\"]\n",
    "    \n",
    "    all_token_ids = []\n",
    "    for tokenized_input in tkds_ids:\n",
    "        all_token_ids.extend(tokenized_input)# + [tokenizer.eos_token_id])\n",
    "    \n",
    "    print(f\"Total number of tokens: {len(all_token_ids)}\")\n",
    "    packed_ds = []\n",
    "    for i in range(0, len(all_token_ids), max_seq_len+1):\n",
    "        input_ids = all_token_ids[i : i + max_seq_len+1]\n",
    "        if len(input_ids) == (max_seq_len+1):\n",
    "            packed_ds.append({\"input_ids\": input_ids[:-1], \"labels\": input_ids[1:]})  # this shift is not needed if using the model.loss\n",
    "    return packed_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c78b4e9-2c7f-4aa1-b738-be04bc55b06b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 3710448\n",
      "Total number of tokens: 286687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7232"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_packed = pack(train_dataset)\n",
    "eval_ds_packed = pack(eval_dataset)\n",
    "len(train_ds_packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54300e7d-4ec9-47a3-898d-9d51ec2d2e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 1131,\n",
       " 3459,\n",
       " 20415,\n",
       " 1128,\n",
       " 13,\n",
       " 164876,\n",
       " 11,\n",
       " 84,\n",
       " 12013,\n",
       " 263,\n",
       " 25327,\n",
       " 18,\n",
       " 26,\n",
       " 45380,\n",
       " 33,\n",
       " 11,\n",
       " 61702,\n",
       " 314,\n",
       " 12970,\n",
       " 22,\n",
       " 15,\n",
       " 10707,\n",
       " 4,\n",
       " 3095,\n",
       " 4,\n",
       " 47187,\n",
       " 4,\n",
       " 7905,\n",
       " 16,\n",
       " 7387,\n",
       " 129,\n",
       " 218322,\n",
       " 16150,\n",
       " 18,\n",
       " 13,\n",
       " 11,\n",
       " 84,\n",
       " 12013,\n",
       " 263,\n",
       " 25327,\n",
       " 18,\n",
       " 26,\n",
       " 45380,\n",
       " 129,\n",
       " 111302,\n",
       " 25,\n",
       " 13,\n",
       " 11,\n",
       " 61702,\n",
       " 314,\n",
       " 12970,\n",
       " 173230,\n",
       " 48,\n",
       " 32,\n",
       " 16150,\n",
       " 18,\n",
       " 22,\n",
       " 15,\n",
       " 10707,\n",
       " 4,\n",
       " 3095,\n",
       " 4,\n",
       " 47187,\n",
       " 4,\n",
       " 7905,\n",
       " 16,\n",
       " 7387,\n",
       " 1131,\n",
       " 54987,\n",
       " 1128,\n",
       " 13,\n",
       " 6,\n",
       " 31735,\n",
       " 22876,\n",
       " 189275,\n",
       " 156140,\n",
       " 42569,\n",
       " 118754,\n",
       " 1131,\n",
       " 9932,\n",
       " 1128,\n",
       " 13,\n",
       " 79469,\n",
       " 69,\n",
       " 25327,\n",
       " 18,\n",
       " 217,\n",
       " 269,\n",
       " 217,\n",
       " 87277,\n",
       " 120,\n",
       " 25327,\n",
       " 18,\n",
       " 2223,\n",
       " 57,\n",
       " 84218,\n",
       " 164876,\n",
       " 11,\n",
       " 84,\n",
       " 12013,\n",
       " 263,\n",
       " 25327,\n",
       " 18,\n",
       " 26,\n",
       " 45380,\n",
       " 33,\n",
       " 11,\n",
       " 61702,\n",
       " 314,\n",
       " 12970,\n",
       " 22,\n",
       " 15,\n",
       " 10707,\n",
       " 4,\n",
       " 3095,\n",
       " 4,\n",
       " 47187,\n",
       " 4,\n",
       " 7905,\n",
       " 16,\n",
       " 7387,\n",
       " 129,\n",
       " 218322,\n",
       " 16150,\n",
       " 18,\n",
       " 13,\n",
       " 11,\n",
       " 84,\n",
       " 12013,\n",
       " 263,\n",
       " 25327,\n",
       " 18,\n",
       " 26,\n",
       " 45380,\n",
       " 129,\n",
       " 111302,\n",
       " 25,\n",
       " 13,\n",
       " 11,\n",
       " 61702,\n",
       " 314,\n",
       " 12970,\n",
       " 173230,\n",
       " 48,\n",
       " 32,\n",
       " 16150,\n",
       " 18,\n",
       " 22,\n",
       " 15,\n",
       " 10707,\n",
       " 4,\n",
       " 3095,\n",
       " 4,\n",
       " 47187,\n",
       " 4,\n",
       " 7905,\n",
       " 16,\n",
       " 7387,\n",
       " 57,\n",
       " 84218,\n",
       " 21854,\n",
       " 16150,\n",
       " 18,\n",
       " 5,\n",
       " 10707,\n",
       " 27824,\n",
       " 4,\n",
       " 16150,\n",
       " 18,\n",
       " 5,\n",
       " 27847,\n",
       " 27824,\n",
       " 4,\n",
       " 16150,\n",
       " 18,\n",
       " 5,\n",
       " 9932,\n",
       " 9023,\n",
       " 27824,\n",
       " 4,\n",
       " 16150,\n",
       " 18,\n",
       " 5,\n",
       " 123506,\n",
       " 27824,\n",
       " 2,\n",
       " 2,\n",
       " 1131,\n",
       " 3459,\n",
       " 20415,\n",
       " 1128,\n",
       " 13,\n",
       " 78222,\n",
       " 32,\n",
       " 121432,\n",
       " 67497,\n",
       " 877,\n",
       " 13984,\n",
       " 501,\n",
       " 32,\n",
       " 8685,\n",
       " 48,\n",
       " 1122,\n",
       " 36858,\n",
       " 5,\n",
       " 1131,\n",
       " 54987,\n",
       " 1128,\n",
       " 13,\n",
       " 6,\n",
       " 31735,\n",
       " 22876,\n",
       " 189275,\n",
       " 156140,\n",
       " 42569,\n",
       " 118754,\n",
       " 1131,\n",
       " 9932,\n",
       " 1128,\n",
       " 13,\n",
       " 79469,\n",
       " 69,\n",
       " 5042,\n",
       " 217,\n",
       " 42425,\n",
       " 217,\n",
       " 269,\n",
       " 217,\n",
       " 13984,\n",
       " 120,\n",
       " 42425,\n",
       " 2223,\n",
       " 57,\n",
       " 84218,\n",
       " 78222,\n",
       " 32,\n",
       " 121432,\n",
       " 67497,\n",
       " 877,\n",
       " 13984,\n",
       " 501,\n",
       " 32,\n",
       " 8685,\n",
       " 48,\n",
       " 1122,\n",
       " 36858,\n",
       " 5,\n",
       " 57,\n",
       " 84218,\n",
       " 1057,\n",
       " 8685,\n",
       " 1131,\n",
       " 763,\n",
       " 58995,\n",
       " 21854,\n",
       " 1515,\n",
       " 90,\n",
       " 69926,\n",
       " 1057,\n",
       " 8685,\n",
       " 1131,\n",
       " 763,\n",
       " 64739,\n",
       " 21854,\n",
       " 41942,\n",
       " 69926,\n",
       " 1057,\n",
       " 8685,\n",
       " 1131,\n",
       " 763,\n",
       " 2843,\n",
       " 13,\n",
       " 21854,\n",
       " 88635,\n",
       " 69926,\n",
       " 1057,\n",
       " 8685,\n",
       " 1131,\n",
       " 763,\n",
       " 6725,\n",
       " 13,\n",
       " 21854,\n",
       " 9763,\n",
       " 69926,\n",
       " 2,\n",
       " 2,\n",
       " 1131,\n",
       " 3459,\n",
       " 20415,\n",
       " 1128,\n",
       " 13,\n",
       " 78222,\n",
       " 17347,\n",
       " 1193,\n",
       " 67,\n",
       " 244514,\n",
       " 69926,\n",
       " 22,\n",
       " 6278,\n",
       " 14837,\n",
       " 1295,\n",
       " 326,\n",
       " 422,\n",
       " 1131,\n",
       " 54987,\n",
       " 1128,\n",
       " 13,\n",
       " 6,\n",
       " 31735,\n",
       " 22876,\n",
       " 189275,\n",
       " 156140,\n",
       " 42569,\n",
       " 118754,\n",
       " 1131,\n",
       " 9932,\n",
       " 1128,\n",
       " 13,\n",
       " 79469,\n",
       " 69,\n",
       " 12259,\n",
       " 217,\n",
       " 172183,\n",
       " 13984,\n",
       " 120,\n",
       " 14837,\n",
       " 2223,\n",
       " 57,\n",
       " 84218,\n",
       " 78222,\n",
       " 17347,\n",
       " 1193,\n",
       " 67,\n",
       " 244514,\n",
       " 69926,\n",
       " 22,\n",
       " 6278,\n",
       " 14837,\n",
       " 1295,\n",
       " 326,\n",
       " 422,\n",
       " 57,\n",
       " 84218,\n",
       " 1057,\n",
       " 146075,\n",
       " 102620,\n",
       " 120,\n",
       " 14837,\n",
       " 4,\n",
       " 77948,\n",
       " 11684,\n",
       " 69926,\n",
       " 2223,\n",
       " 21854,\n",
       " 1506,\n",
       " 120,\n",
       " 217,\n",
       " 12259,\n",
       " 217,\n",
       " 172183,\n",
       " 13984,\n",
       " 120,\n",
       " 290,\n",
       " 5,\n",
       " 11098,\n",
       " 69926,\n",
       " 16,\n",
       " 73,\n",
       " 624,\n",
       " 22,\n",
       " 84,\n",
       " 18,\n",
       " 5,\n",
       " 15471,\n",
       " 7,\n",
       " 16,\n",
       " 85,\n",
       " 2311,\n",
       " 146075,\n",
       " 102620,\n",
       " 120,\n",
       " 14837,\n",
       " 4,\n",
       " 62348,\n",
       " 42,\n",
       " 69926,\n",
       " 2223,\n",
       " 21854,\n",
       " 69,\n",
       " 12259,\n",
       " 217,\n",
       " 172183,\n",
       " 13984,\n",
       " 140635,\n",
       " 14837,\n",
       " 5,\n",
       " 65648,\n",
       " 69926,\n",
       " 16,\n",
       " 16,\n",
       " 85,\n",
       " 2311,\n",
       " 146075,\n",
       " 102620,\n",
       " 120,\n",
       " 14837,\n",
       " 4,\n",
       " 27401,\n",
       " 69926,\n",
       " 2223,\n",
       " 21854,\n",
       " 69,\n",
       " 12259,\n",
       " 217,\n",
       " 172183,\n",
       " 13984,\n",
       " 120,\n",
       " 14837,\n",
       " 5,\n",
       " 18550,\n",
       " 69926,\n",
       " 16,\n",
       " 326,\n",
       " 69,\n",
       " 12259,\n",
       " 217,\n",
       " 172183,\n",
       " 13984,\n",
       " 120,\n",
       " 14837,\n",
       " 5,\n",
       " 145429,\n",
       " 69926,\n",
       " 16,\n",
       " 12515,\n",
       " 13,\n",
       " 21854,\n",
       " 146075,\n",
       " 102620,\n",
       " 120,\n",
       " 14837,\n",
       " 4,\n",
       " 244514,\n",
       " 69926,\n",
       " 16,\n",
       " 2,\n",
       " 2,\n",
       " 1131,\n",
       " 3459,\n",
       " 20415,\n",
       " 1128,\n",
       " 13,\n",
       " 164876,\n",
       " 11,\n",
       " 59952,\n",
       " 501,\n",
       " 134967,\n",
       " 33,\n",
       " 46,\n",
       " 128769,\n",
       " 1131,\n",
       " 54987,\n",
       " 1128,\n",
       " 13,\n",
       " 6,\n",
       " 31735,\n",
       " 22876,\n",
       " 189275,\n",
       " 156140,\n",
       " 42569,\n",
       " 118754,\n",
       " 1131,\n",
       " 9932,\n",
       " 1128,\n",
       " 13,\n",
       " 79469,\n",
       " 33,\n",
       " 217,\n",
       " 87344,\n",
       " 217,\n",
       " 148350,\n",
       " 120,\n",
       " 148350,\n",
       " 2223,\n",
       " 57,\n",
       " 84218,\n",
       " 164876,\n",
       " 11,\n",
       " 59952,\n",
       " 501,\n",
       " 134967,\n",
       " 33,\n",
       " 46,\n",
       " 128769,\n",
       " 57,\n",
       " 84218,\n",
       " 19772,\n",
       " 13672,\n",
       " 87344,\n",
       " 157,\n",
       " 205,\n",
       " 73865,\n",
       " 1269,\n",
       " 298,\n",
       " 725,\n",
       " 5,\n",
       " 15471,\n",
       " 120,\n",
       " 15471,\n",
       " 5,\n",
       " 8187]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_packed[0][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df389230-911c-447c-a177-a18c22837020",
   "metadata": {},
   "source": [
    "Doing so, we end up with a little more than 11k sequences of lenght 1024. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43713b3-9f65-42a6-8338-ab0601e5f476",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f342873a-29a3-4ed1-8b59-9e7f7f2a4c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "batch_size = 2\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_ds_packed,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=default_data_collator,\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_ds_packed,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=default_data_collator,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ccaf4-dfa1-4daa-9a6f-244c8cda7818",
   "metadata": {},
   "source": [
    "It is always a good idea to check how does a batch looks like, you can quickly do this by sampling from the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffced7ec-bd1b-42b0-be64-04f3fae5df84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,  1131,  3459,  ..., 15471,     5,  8187],\n",
       "         [   33,   217, 87344,  ...,  2223,    57, 84218]]),\n",
       " 'labels': tensor([[  1131,   3459,  20415,  ...,      5,   8187,      4],\n",
       "         [   217,  87344,    217,  ...,     57,  84218, 140821]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = next(iter(train_dataloader))\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d15d30-58d2-465d-a9f4-be0eef2ea06b",
   "metadata": {},
   "source": [
    "We can alos decode the batch just to be super sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28e18ad2-c141-4902-a5a4-24a1e743be35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s> <context>: Convert a dlib\\'rect\\' object to a plain tuple in (top, right, bottom, left) order :param rect: a dlib\\'rect\\' object :return: a plain tuple representation of the rect in (top, right, bottom, left) order <human>: เขียนโค้ดโดยใช้ภาษา Python <bot>:def _rect_to_css(rect): \"\"\" Convert a dlib\\'rect\\' object to a plain tuple in (top, right, bottom, left) order :param rect: a dlib\\'rect\\' object :return: a plain tuple representation of the rect in (top, right, bottom, left) order \"\"\" return rect.top(), rect.right(), rect.bottom(), rect.left()</s></s> <context>: Return the Catalyst datatype from the size of integers. <human>: เขียนโค้ดโดยใช้ภาษา Python <bot>:def _int_size_to_type(size): \"\"\" Return the Catalyst datatype from the size of integers. \"\"\" if size <= 8: return ByteType if size <= 16: return ShortType if size <= 32: return IntegerType if size <= 64: return LongType</s></s> <context>: Return whether there is NullType in `dt` or not <human>: เขียนโค้ดโดยใช้ภาษา Python <bot>:def _has_nulltype(dt): \"\"\" Return whether there is NullType in `dt` or not \"\"\" if isinstance(dt, StructType): return any(_has_nulltype(f.dataType) for f in dt.fields) elif isinstance(dt, ArrayType): return _has_nulltype((dt.elementType)) elif isinstance(dt, MapType): return _has_nulltype(dt.keyType) or _has_nulltype(dt.valueType) else: return isinstance(dt, NullType)</s></s> <context>: Convert a schema from Spark to Arrow <human>: เขียนโค้ดโดยใช้ภาษา Python <bot>:def to_arrow_schema(schema): \"\"\" Convert a schema from Spark to Arrow \"\"\" import pyarrow as pa fields = [pa.field(field.name'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(b[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0a46e93-7ec2-4365-8e50-be7bef873436",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<context>: Convert a dlib'rect' object to a plain tuple in (top, right, bottom, left) order :param rect: a dlib'rect' object :return: a plain tuple representation of the rect in (top, right, bottom, left) order <human>: เขียนโค้ดโดยใช้ภาษา Python <bo\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(b[\"labels\"][0])[:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99a7dc-0654-4985-ac3f-60ecdc6f6558",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757e458-14fd-4dd3-861f-efad04dce787",
   "metadata": {},
   "source": [
    "I like storing all my hyperparameters into a `SimpleNamespace`, it's like a dict but with .dot attribute access. Then I can access my batch size by doing config.batch_size instead of config[\"batch_size\"]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6925a62e-d85e-4c86-8867-bee3a180fc08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "gradient_accumulation_steps = 2\n",
    "model_id= r'C:\\Users\\ryu\\Desktop\\llm\\finetune-wangchai-11212023\\base_model'\n",
    "\n",
    "config = SimpleNamespace(\n",
    "    model_id=model_id,\n",
    "    dataset_name=\"alpaca-gpt4\",\n",
    "    precision=\"bf16\",  # faster and better than fp16, requires new GPUs\n",
    "    n_freeze=14,  # How many layers we don't train, LLama 7B has 32.\n",
    "    lr=2e-4,\n",
    "    n_eval_samples=10, # How many samples to generate on validation\n",
    "    max_seq_len=max_sequence_len, # Lenght of the sequences to pack\n",
    "    epochs=3,  # we do 3 pasess over the dataset.\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,  # evey how many iterations we update the gradients, simulates larger batch sizes\n",
    "    batch_size=batch_size,  # what my GPU can handle, depends on how many layers are we training  \n",
    "    log_model=False,  # upload the model to W&B?\n",
    "    gradient_checkpointing = True,  # saves even more memory\n",
    "    freeze_embed = False,  # why train this? let's keep them frozen ❄️\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "config.total_train_steps = config.epochs * len(train_dataloader) // config.gradient_accumulation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a7166a6-8e88-4f0d-bc0e-70aac292c645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will train for 5424 steps and evaluate every epoch\n"
     ]
    }
   ],
   "source": [
    "print(f\"We will train for {config.total_train_steps} steps and evaluate every epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcd0229-5e4c-4bb5-827b-309bdbb351df",
   "metadata": {},
   "source": [
    "We first get a pretrained model with some configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51c10f7f-2551-4aa4-aef2-29c888b57a12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fd64f8ec0e4f1fb171d850827be3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.model_id,\n",
    "    device_map=0,\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2955b71e-350c-4de6-8e51-1a2af3dc52eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(256008, 4096, padding_idx=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc6c3959-854c-409e-9037-b5c87a6adce5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 7492.77M, Trainable: 7492.77M\n"
     ]
    }
   ],
   "source": [
    "def param_count(m):\n",
    "    params = sum([p.numel() for p in m.parameters()])/1_000_000\n",
    "    trainable_params = sum([p.numel() for p in m.parameters() if p.requires_grad])/1_000_000\n",
    "    print(f\"Total params: {params:.2f}M, Trainable: {trainable_params:.2f}M\")\n",
    "    return params, trainable_params\n",
    "\n",
    "params, trainable_params = param_count(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79dbbb0-6dac-4f78-a862-8201088c9d57",
   "metadata": {},
   "source": [
    "Training the full models is expensive, but if you have a GPU that can fit the full model, you can skip this part. Let's just train the last 8 layers of the model (Llama2-7B has 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c4de41e-5c10-478b-9524-f4a3119d277c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# freeze layers (disable gradients)\n",
    "for param in model.parameters(): param.requires_grad = False\n",
    "for param in model.lm_head.parameters(): param.requires_grad = True\n",
    "for param in model.model.layers[config.n_freeze:].parameters(): param.requires_grad = True\n",
    "#for name, param in model.named_parameters():\n",
    "#    if (name == \"model.embed_tokens.weight\"):\n",
    "#        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd7fc941-65dc-4dee-839d-351bd019a2fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just freeze embeddings for small memory decrease\n",
    "#if config.freeze_embed:\n",
    "#    model.model.embed_tokens.weight.requires_grad_(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284599f6-ba88-4172-a311-8e618f716b30",
   "metadata": {},
   "source": [
    "and you can also use gradient checkpointing to save even more (this makes training slower, how much it will depend on your particular configuration). There is a [nice article](https://huggingface.co/docs/transformers/v4.18.0/en/performance) on the Huggingface website about how to fit large models on memory, I encourage you to check it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "750ce64e-0088-4ca8-9bc9-60037e7110d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save more memory\n",
    "#if config.gradient_checkpointing:\n",
    "#    model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6232ce7a-b847-45c8-8ff7-e36249e7a060",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 7492.77M, Trainable: 4673.45M\n"
     ]
    }
   ],
   "source": [
    "params, trainable_params = param_count(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc92663c-95a4-4ecc-a9af-7a68d9648271",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "We setup the standard optimization stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5374c44d-517b-42a0-ade6-297c0a5d18b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=config.lr, betas=(0.9,0.99), eps=1e-5)\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optim,\n",
    "    num_training_steps=config.total_train_steps,\n",
    "    num_warmup_steps=config.total_train_steps // 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5efdd402-c851-47a5-9134-5b47b7d118e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(x, y):\n",
    "    \"A Flat CrossEntropy\" \n",
    "    return torch.nn.functional.cross_entropy(x.view(-1, x.shape[-1]), y.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24440392-9837-4cbb-873a-372f9f5aca20",
   "metadata": {},
   "source": [
    "## Testing during training\n",
    "\n",
    "We are almost there, let's create a simple function to sample from the model now and then, to visualy see what the models is outputting!\n",
    "Let's wrap the model.generate method for simplicity. You can grab the defaults sampling parameters from the GenerationConfig and passing the corresponding model_id. This will grab you the defaults for parameters like temperature, top p, etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0a92fe7-3f9e-43e6-80b0-adbbd8b480ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "gen_config = GenerationConfig.from_pretrained(config.model_id)\n",
    "test_config = SimpleNamespace(\n",
    "    max_new_tokens=256,\n",
    "    gen_config=gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ec41718-52c6-4335-a534-2790d03ba069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(prompt, max_new_tokens=test_config.max_new_tokens, gen_config=gen_config):\n",
    "    tokenized_prompt = tokenizer(prompt, return_tensors='pt')['input_ids'].cuda()\n",
    "    with torch.inference_mode():\n",
    "        output = model.generate(tokenized_prompt, \n",
    "                            max_new_tokens=max_new_tokens, \n",
    "                            generation_config=gen_config)\n",
    "    return tokenizer.decode(output[0][len(tokenized_prompt[0]):], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44601edc-db5b-40ea-bb74-9591ea4e7e50",
   "metadata": {},
   "source": [
    "LoL 🤷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4e39c49-ccb1-4fe6-aa30-988ea5583b99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<context>: What a Terrible Failure! <human>: เขียนโค้ดโดยใช้ภาษา Python <bot>:นี่คือโค้ดบางส่วนสําหรับสร้างรายการ `a` ใหม่จากรายการ `b` ใหม่ b.replace('a', 'b') #คําเตือน: การสร้างรหัสนี้เป็นการทดลอง โปรดตรวจสอบโค้ดเพื่อหาข้อผิดพลาดก่อนดําเนินการ\n"
     ]
    }
   ],
   "source": [
    "prompt = eval_dataset[14][\"prompt\"]\n",
    "print(prompt + generate(prompt, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567920c0-005d-419d-98ab-4d797b243300",
   "metadata": {},
   "source": [
    "We can log a Table with those results to the project every X steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bac25c48-cb18-4560-b05c-1748e7d1adf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def prompt_table(examples, log=False, table_name=\"predictions\"):\n",
    "    table = wandb.Table(columns=[\"prompt\", \"generation\", \"concat\", \"output\", \"max_new_tokens\", \"temperature\", \"top_p\"])\n",
    "    for example in tqdm(examples, leave=False):\n",
    "        prompt, gpt4_output = example[\"prompt\"], example[\"output\"]\n",
    "        out = generate(prompt, test_config.max_new_tokens, test_config.gen_config)\n",
    "        table.add_data(prompt, out, prompt+out, gpt4_output, test_config.max_new_tokens, test_config.gen_config.temperature, test_config.gen_config.top_p)\n",
    "    if log:\n",
    "        wandb.log({table_name:table})\n",
    "    return table\n",
    "\n",
    "def to_gpu(tensor_dict):\n",
    "    return {k: v.to('cuda') for k, v in tensor_dict.items()}\n",
    "\n",
    "class Accuracy:\n",
    "    \"A simple Accuracy function compatible with HF models\"\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.tp = 0.\n",
    "    def update(self, logits, labels):\n",
    "        logits, labels = logits.argmax(dim=-1).view(-1).cpu(), labels.view(-1).cpu()\n",
    "        tp = (logits == labels).sum()\n",
    "        self.count += len(logits)\n",
    "        self.tp += tp\n",
    "        return tp / len(logits)\n",
    "    def compute(self):\n",
    "        return self.tp / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52fbc09-5d65-4265-abce-adda01d85584",
   "metadata": {},
   "source": [
    "You can also quickly add validation if you feel so, the table can be also created at this step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6891b2c0-f22e-4647-9ac2-e07a994f3e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate():\n",
    "    model.eval();\n",
    "    eval_acc = Accuracy()\n",
    "    loss, total_steps = 0., 0\n",
    "    for step, batch in enumerate(pbar:=tqdm(eval_dataloader, leave=False)):\n",
    "        pbar.set_description(f\"doing validation\")\n",
    "        batch = to_gpu(batch)\n",
    "        total_steps += 1\n",
    "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            out = model(**batch)\n",
    "            loss += loss_fn(out.logits, batch[\"labels\"])  # you could use out.loss and not shift the dataset\n",
    "        eval_acc.update(out.logits, batch[\"labels\"])\n",
    "    # we log results at the end\n",
    "    wandb.log({\"eval/loss\": loss.item() / total_steps,\n",
    "               \"eval/accuracy\": eval_acc.compute()})\n",
    "    prompt_table(eval_dataset[:config.n_eval_samples], log=True)\n",
    "    model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37364791-987e-4e81-9621-3094ed5bf86d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def save_model(model, model_name, models_folder=\"models\", log=False):\n",
    "    \"\"\"Save the model to wandb as an artifact\n",
    "    Args:\n",
    "        model (nn.Module): Model to save.\n",
    "        model_name (str): Name of the model.\n",
    "        models_folder (str, optional): Folder to save the model. Defaults to \"models\".\n",
    "    \"\"\"\n",
    "    model_name = f\"{wandb.run.id}_{model_name}\"\n",
    "    file_name = Path(f\"{models_folder}/{model_name}\")\n",
    "    file_name.parent.mkdir(parents=True, exist_ok=True)\n",
    "    model.save_pretrained(file_name, safe_serialization=True)\n",
    "    # save tokenizer for easy inference\n",
    "    #tokenizer = AutoTokenizer.from_pretrained(model.name_or_path)\n",
    "    #tokenizer.save_pretrained(model_name)\n",
    "    if log:\n",
    "        at = wandb.Artifact(model_name, type=\"model\")\n",
    "        at.add_dir(file_name)\n",
    "        wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93834c0b-15e1-4e43-8535-dbb9f36af29d",
   "metadata": {},
   "source": [
    "Let's define a loop that compute evaluation and logs a Table with model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90177c-0c5a-48e7-9a39-2b9e67794814",
   "metadata": {},
   "source": [
    "## The actual Loop\n",
    "It's actually nothing fancy, and very short! It has:\n",
    "- Gradient accumulation and gradient scaling\n",
    "- sampling and model checkpoint saving (this trains very fast, no need to save multiple checkpoints)\n",
    "- We compute token accuracy, better metric than loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75078a-5d35-46bc-8f33-0e3adf52d072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mryuinw123\u001b[0m (\u001b[33mllm-courseville\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ryu\\Desktop\\llm\\finetune-wangchai-11212023\\wandb\\run-20231126_183140-f0a4e3w2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/llm-courseville/wangchangGLM-finetune-gpt4/runs/f0a4e3w2' target=\"_blank\">colorful-butterfly-35</a></strong> to <a href='https://wandb.ai/llm-courseville/wangchangGLM-finetune-gpt4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/llm-courseville/wangchangGLM-finetune-gpt4' target=\"_blank\">https://wandb.ai/llm-courseville/wangchangGLM-finetune-gpt4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/llm-courseville/wangchangGLM-finetune-gpt4/runs/f0a4e3w2' target=\"_blank\">https://wandb.ai/llm-courseville/wangchangGLM-finetune-gpt4/runs/f0a4e3w2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544cb78896ad4689804b944afe463c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f26f6ac5fa544e98d784ebe441ed7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e5b6f0420a4bd797cbc4bb6c03ebc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"wangchangGLM-finetune-gpt4\", # the project I am working on\n",
    "           tags=[\"baseline\",\"7b\"],\n",
    "           job_type=\"train\",\n",
    "           config=config) # the Hyperparameters I want to keep track of\n",
    "\n",
    "# Training\n",
    "acc = Accuracy()\n",
    "model.train()\n",
    "train_step = 0\n",
    "for epoch in tqdm(range(config.epochs)):\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = to_gpu(batch)\n",
    "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            out = model(**batch)\n",
    "            loss = loss_fn(out.logits, batch[\"labels\"]) / config.gradient_accumulation_steps  # you could use out.loss and not shift the dataset  \n",
    "            loss.backward()\n",
    "        if step%config.gradient_accumulation_steps == 0:\n",
    "            # we can log the metrics to W&B\n",
    "            wandb.log({\"train/loss\": loss.item() * config.gradient_accumulation_steps,\n",
    "                       \"train/accuracy\": acc.update(out.logits, batch[\"labels\"]),\n",
    "                       \"train/learning_rate\": scheduler.get_last_lr()[0],\n",
    "                       \"train/global_step\": train_step})\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            train_step += 1\n",
    "    validate()\n",
    "    save_model(model, model_name=f\"wangchai_{epoch+1}\", models_folder=\"models/\", log=config.log_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099bc28-e695-46a6-994c-b612f7811937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we save the model checkpoint at the end    \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3057c03-4d6b-4700-bf79-53fbba069048",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login --token \"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\"\n",
    "\n",
    "new_model = \"ryuinw123/wangchanglm-finetune-epoch3\"\n",
    "model.push_to_hub(new_model)\n",
    "tokenizer.push_to_hub(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936e007-47fa-400f-873c-5e038bd685c5",
   "metadata": {},
   "source": [
    "## Full Eval Dataset evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399fafb9-b41f-401b-a1c4-37e1ede2e639",
   "metadata": {},
   "source": [
    "Let's log a table with model predictions on the eval_dataset (or at least the 250 first samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89717a-ac70-43e8-9b7c-edd8d2c54cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with wandb.init(project=\"alpaca_ft\", # the project I am working on\n",
    "           job_type=\"eval\",\n",
    "           config=config): # the Hyperparameters I want to keep track of\n",
    "    model.eval();\n",
    "    prompt_table(eval_dataset[:250], log=True, table_name=\"eval_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05cc4d4-416b-4ebb-9954-96185a56ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Propose two possible solutions to a company that wants to improve its customer service.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0043c-a43b-46d3-a014-c940d940fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[60][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d34e9-b8d1-48e7-9994-ec3e27944abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(train_dataset[60][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85378e5-8589-41c4-a06a-3967139c09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[60][\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7cc4c-0765-4103-aeec-c19478078140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[6][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e709ff6-2331-4db9-9fe1-ca01811c0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(train_dataset[6][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00edd8-bda4-430c-9e28-5b6cdc2db9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[6][\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070fadd-2e9f-4428-899a-c8d36483304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eebf91-a867-468e-92f9-4ee6421f298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_acc = Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f189806-11c2-4902-9cc8-df9b6dcf0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, total_steps = 0., 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25273f53-59e5-4bd0-b998-4aeebbc8a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, batch in enumerate(pbar:=tqdm(eval_dataloader, leave=False)):\n",
    "    pbar.set_description(f\"doing validation\")\n",
    "    print(\"step = \" , step)\n",
    "    print(\"Before batch\" , batch)\n",
    "    batch = to_gpu(batch)\n",
    "    print(\"After batch\" , batch)\n",
    "    with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "        out = model(**batch)\n",
    "        print(out)\n",
    "        loss += loss_fn(out.logits, batch[\"labels\"])  # you could use out.loss and not shift the dataset\n",
    "        print(\"loss = \" , loss , \"loss item = \" , loss.item())\n",
    "    print(\"before out\" ,out.logits , batch[\"labels\"])\n",
    "    logits, labels = out.logits.argmax(dim=-1).view(-1).cpu(), batch[\"labels\"].view(-1).cpu()\n",
    "    print(\"after out\" ,logits , labels)\n",
    "    tp = (logits == labels).sum()\n",
    "    print(tp / len(logits))\n",
    "    #print(eval_acc.compute())\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3ecfb-fbfe-4127-b9cb-a462a390e927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
