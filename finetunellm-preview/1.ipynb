{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3718024c-a915-4111-af71-efa63899e52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/peft.git"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git 'C:\\Users\\ryu\\AppData\\Local\\Temp\\pip-req-build-k8ecd30a'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/huggingface/peft.git to c:\\users\\ryu\\appdata\\local\\temp\\pip-req-build-k8ecd30a\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 5d84484079ee72c92678eadb273d3fe0241ed5ea\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from peft==0.6.2.dev0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from peft==0.6.2.dev0) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from peft==0.6.2.dev0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from peft==0.6.2.dev0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from peft==0.6.2.dev0) (2.1.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from peft==0.6.2.dev0) (4.36.0.dev0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from peft==0.6.2.dev0) (4.66.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from peft==0.6.2.dev0) (0.25.0.dev0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from peft==0.6.2.dev0) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from accelerate>=0.21.0->peft==0.6.2.dev0) (0.17.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.13.0->peft==0.6.2.dev0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.13.0->peft==0.6.2.dev0) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.13.0->peft==0.6.2.dev0) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.13.0->peft==0.6.2.dev0) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.13.0->peft==0.6.2.dev0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.13.0->peft==0.6.2.dev0) (2023.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from tqdm->peft==0.6.2.dev0) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from transformers->peft==0.6.2.dev0) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from transformers->peft==0.6.2.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from transformers->peft==0.6.2.dev0) (0.14.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from jinja2->torch>=1.13.0->peft==0.6.2.dev0) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from requests->transformers->peft==0.6.2.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from requests->transformers->peft==0.6.2.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from requests->transformers->peft==0.6.2.dev0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from requests->transformers->peft==0.6.2.dev0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from sympy->torch>=1.13.0->peft==0.6.2.dev0) (1.3.0)\n",
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to c:\\users\\ryu\\appdata\\local\\temp\\pip-req-build-luqem_37\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit fc0a43c3c1235f1540b5401e03a1710fb72fb8e9\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from accelerate==0.25.0.dev0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from accelerate==0.25.0.dev0) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from accelerate==0.25.0.dev0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from accelerate==0.25.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from accelerate==0.25.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from accelerate==0.25.0.dev0) (0.17.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from accelerate==0.25.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from huggingface-hub->accelerate==0.25.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from huggingface-hub->accelerate==0.25.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate==0.25.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate==0.25.0.dev0) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git 'C:\\Users\\ryu\\AppData\\Local\\Temp\\pip-req-build-luqem_37'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trl in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (0.7.4)\n",
      "Requirement already satisfied: xformers in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (0.0.22.post7)\n",
      "Requirement already satisfied: wandb in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (2.14.6)\n",
      "Requirement already satisfied: einops in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: gradio in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (0.1.99)\n",
      "Requirement already satisfied: transformers in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (4.36.0.dev0)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from trl) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from trl) (1.26.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from trl) (0.25.0.dev0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from trl) (0.5.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.4.0->trl) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.4.0->trl) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.4.0->trl) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.4.0->trl) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.4.0->trl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from torch>=1.4.0->trl) (2023.10.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from wandb) (1.34.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from wandb) (4.25.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from datasets) (14.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (5.1.2)\n",
      "Requirement already satisfied: fastapi in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (0.104.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.7.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (0.7.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (6.1.1)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (3.8.1)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (3.9.10)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (10.0.1)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (2.4.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (0.24.0.post1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from aiohttp->datasets) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from pydantic>=2.0->gradio) (2.10.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (13.6.0)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from tyro>=0.5.11->trl) (0.15)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from tyro>=0.5.11->trl) (1.6.4)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from fastapi->gradio) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from httpx->gradio) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
      "Collecting bitsandbytes==0.41.0\n",
      "  Downloading https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.0-py3-none-win_amd64.whl (152.7 MB)\n",
      "     ---------------------------------------- 0.0/152.7 MB ? eta -:--:--\n",
      "     -------------------------------------- 0.0/152.7 MB 660.6 kB/s eta 0:03:52\n",
      "     ---------------------------------------- 0.6/152.7 MB 8.1 MB/s eta 0:00:19\n",
      "     --------------------------------------- 1.9/152.7 MB 15.1 MB/s eta 0:00:11\n",
      "      -------------------------------------- 3.9/152.7 MB 22.8 MB/s eta 0:00:07\n",
      "     - ------------------------------------- 6.7/152.7 MB 30.7 MB/s eta 0:00:05\n",
      "     -- ----------------------------------- 11.0/152.7 MB 59.5 MB/s eta 0:00:03\n",
      "     ---- -------------------------------- 16.6/152.7 MB 108.8 MB/s eta 0:00:02\n",
      "     ----- ------------------------------- 22.3/152.7 MB 108.8 MB/s eta 0:00:02\n",
      "     ------ ------------------------------ 27.9/152.7 MB 110.0 MB/s eta 0:00:02\n",
      "     -------- ---------------------------- 33.6/152.7 MB 110.0 MB/s eta 0:00:02\n",
      "     --------- --------------------------- 39.2/152.7 MB 108.8 MB/s eta 0:00:02\n",
      "     ---------- -------------------------- 44.7/152.7 MB 108.8 MB/s eta 0:00:01\n",
      "     ----------- ------------------------- 49.3/152.7 MB 108.8 MB/s eta 0:00:01\n",
      "     ------------- ----------------------- 56.0/152.7 MB 131.2 MB/s eta 0:00:01\n",
      "     -------------- ---------------------- 61.6/152.7 MB 108.8 MB/s eta 0:00:01\n",
      "     ---------------- -------------------- 67.2/152.7 MB 108.8 MB/s eta 0:00:01\n",
      "     ----------------- ------------------- 72.8/152.7 MB 110.0 MB/s eta 0:00:01\n",
      "     ------------------- ----------------- 78.5/152.7 MB 110.0 MB/s eta 0:00:01\n",
      "     -------------------- ---------------- 84.1/152.7 MB 108.8 MB/s eta 0:00:01\n",
      "     --------------------- --------------- 89.7/152.7 MB 108.8 MB/s eta 0:00:01\n",
      "     ----------------------- ------------- 95.2/152.7 MB 108.8 MB/s eta 0:00:01\n",
      "     ----------------------- ------------ 100.9/152.7 MB 108.8 MB/s eta 0:00:01\n",
      "     ------------------------- ---------- 106.5/152.7 MB 131.2 MB/s eta 0:00:01\n",
      "     -------------------------- --------- 112.2/152.7 MB 129.5 MB/s eta 0:00:01\n",
      "     --------------------------- -------- 117.8/152.7 MB 131.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ------ 123.4/152.7 MB 131.2 MB/s eta 0:00:01\n",
      "     ------------------------------ ----- 129.1/152.7 MB 131.2 MB/s eta 0:00:01\n",
      "     ------------------------------- ---- 134.7/152.7 MB 131.2 MB/s eta 0:00:01\n",
      "     --------------------------------- -- 140.3/152.7 MB 131.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- - 146.0/152.7 MB 131.2 MB/s eta 0:00:01\n",
      "     -----------------------------------  151.4/152.7 MB 131.2 MB/s eta 0:00:01\n",
      "     -----------------------------------  152.7/152.7 MB 110.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  152.7/152.7 MB 110.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  152.7/152.7 MB 110.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- 152.7/152.7 MB 40.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from bitsandbytes==0.41.0) (1.11.3)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from scipy->bitsandbytes==0.41.0) (1.26.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipywidgets) (8.17.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipywidgets) (5.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: decorator in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.40)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.9)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ryu\\.conda\\envs\\llm\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install trl xformers wandb datasets einops gradio sentencepiece transformers\n",
    "!pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.0-py3-none-win_amd64.whl\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254e41d3-d2d9-4594-878d-39bde9939de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\ryu\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97b9ccc-ad49-4aa1-98e5-25cc215ae1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin C:\\Users\\ryu\\.conda\\envs\\llm\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121.dll\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryu\\.conda\\envs\\llm\\Lib\\site-packages\\trl\\trainer\\ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, pipeline, logging, TextStreamer\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os,torch, wandb, platform, gradio, warnings\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedd68f2-b455-4db7-9f5c-0dad878e0dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Number of CUDA devices: 1\n",
      "--- CUDA Device 0 ---\n",
      "Name: NVIDIA GeForce RTX 3090 Ti\n",
      "Compute Capability: (8, 6)\n",
      "Total Memory: 25756696576 bytes\n",
      "--- CPU Information ---\n",
      "Processor: AMD64 Family 25 Model 33 Stepping 0, AuthenticAMD\n",
      "System: Windows 10\n",
      "Python Version: 3.11.5\n"
     ]
    }
   ],
   "source": [
    "def print_system_specs():\n",
    "    # Check if CUDA is available\n",
    "    is_cuda_available = torch.cuda.is_available()\n",
    "    print(\"CUDA Available:\", is_cuda_available)\n",
    "# Get the number of available CUDA devices\n",
    "    num_cuda_devices = torch.cuda.device_count()\n",
    "    print(\"Number of CUDA devices:\", num_cuda_devices)\n",
    "    if is_cuda_available:\n",
    "        for i in range(num_cuda_devices):\n",
    "            # Get CUDA device properties\n",
    "            device = torch.device('cuda', i)\n",
    "            print(f\"--- CUDA Device {i} ---\")\n",
    "            print(\"Name:\", torch.cuda.get_device_name(i))\n",
    "            print(\"Compute Capability:\", torch.cuda.get_device_capability(i))\n",
    "            print(\"Total Memory:\", torch.cuda.get_device_properties(i).total_memory, \"bytes\")\n",
    "    # Get CPU information\n",
    "    print(\"--- CPU Information ---\")\n",
    "    print(\"Processor:\", platform.processor())\n",
    "    print(\"System:\", platform.system(), platform.release())\n",
    "    print(\"Python Version:\", platform.python_version())\n",
    "print_system_specs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3af83db-f118-42b6-8b78-395831efe178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre trained model\n",
    "model_name = \"pythainlp/wangchanglm-7.5B-sft-enth\"\n",
    "# Dataset name\n",
    "dataset_name = \"open-phi/programming_books_llama\"\n",
    "\n",
    "# Hugging face repository link to save fine-tuned model(Create new repository in huggingface,copy and paste here)\n",
    "new_model = \"ryuinw123/test-finetune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "498c8284-4a51-4187-b11e-3f5a03810367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7556971b9fda462c85b938c9ac799d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e018d17-1480-42e8-9af3-7598f7a0e1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# Understanding derivatives and their role in algorithms\n",
      "\n",
      "Derivatives are a fundamental concept in calculus and play a crucial role in many algorithms used in computer science. At its core, a derivative measures the rate of change of a function at a particular point. This rate of change can be interpreted as the slope of the function's graph at that point.\n",
      "\n",
      "Derivatives are used in various algorithms for tasks such as optimization, machine learning, and data analysis. By understanding derivatives, we can better understand how these algorithms work and how to improve their efficiency.\n",
      "\n",
      "To compute a derivative, we use the concept of a limit. A limit allows us to determine the behavior of a function as the input approaches a certain value. In the context of derivatives, we are interested in the limit as the difference between two input values approaches zero. This difference is often denoted as \"h\" and represents a small change in the input.\n",
      "\n",
      "The derivative of a function f(x) at a point x is defined as the limit of the difference quotient:\n",
      "\n",
      "$$\\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}$$\n",
      "\n",
      "This difference quotient represents the average rate of change of the function over a small interval. As h approaches zero, the difference quotient becomes the instantaneous rate of change, which is the derivative.\n",
      "\n",
      "Let's consider the function f(x) = x^2. We can compute the derivative of this function using the limit definition:\n",
      "\n",
      "$$\\lim_{h \\to 0} \\frac{(x + h)^2 - x^2}{h}$$\n",
      "\n",
      "Expanding and simplifying the numerator, we get:\n",
      "\n",
      "$$\\lim_{h \\to 0} \\frac{x^2 + 2xh + h^2 - x^2}{h}$$\n",
      "\n",
      "Canceling out the x^2 terms, we have:\n",
      "\n",
      "$$\\lim_{h \\to 0} \\frac{2xh + h^2}{h}$$\n",
      "\n",
      "Simplifying further, we get:\n",
      "\n",
      "$$\\lim_{h \\to 0} 2x + h$$\n",
      "\n",
      "Taking the limit as h approaches zero, we find that the derivative of f(x) = x^2 is 2x.\n",
      "\n",
      "## Exercise\n",
      "Compute the derivative of the function f(x) = 3x^3 - 2x^2 + 5x - 1.\n",
      "\n",
      "### Solution\n",
      "Using the limit definition of the derivative, we can compute the difference quotient:\n",
      "\n",
      "$$\\lim_{h \\to 0} \\frac{(x + h)^3 - (3x^3 - 2x^2 + 5x - 1)}{h}$$\n",
      "\n",
      "Expanding and simplifying the numerator, we get:\n",
      "\n",
      "$$\\lim_{h \\to 0} \\frac{x^3 + 3x^2h + 3xh^2 + h^3 - 3x^3 + 2x^2 - 5x + 1}{h}$$\n",
      "\n",
      "Canceling out the x^3, x^2, and x terms, we have:\n",
      "\n",
      "$$\\lim_{h \\to 0} \\frac{3x^2h + 3xh^2 + h^3 + 2x^2 - 5x + 1}{h}$$\n",
      "\n",
      "Simplifying further, we get:\n",
      "\n",
      "$$\\lim_{h \\to 0} 3x^2 + 3xh + h^2 + 2x - 5$$\n",
      "\n",
      "Taking the limit as h approaches zero, we find that the derivative of f(x) = 3x^3 - 2x^2 + 5x - 1 is 3x^2 + 2x - 5.\n",
      "\n",
      "# Exploring limits and their significance in computational complexity\n",
      "\n",
      "Limits are a fundamental concept in calculus that allow us to understand the behavior of functions as their inputs approach certain values. In the context of computational complexity, limits play a significant role in analyzing the efficiency of algorithms.\n",
      "\n",
      "When analyzing the time or space complexity of an algorithm, we often want to know how the algorithm behaves as the input size grows to infinity. This is where limits come into play. By taking the limit of a function that represents the algorithm's complexity, we can determine its growth rate and make comparisons between different algorithms.\n",
      "\n",
      "One common example is the analysis of sorting algorithms. Sorting a list of numbers is a fundamental task in computer science, and there are many different algorithms available. To compare the efficiency of these algorithms, we can analyze their time complexity using limits.\n",
      "\n",
      "The time complexity of an algorithm is often expressed using big O notation, which provides an upper bound on the growth rate of the algorithm's running time. For example, the bubble sort algorithm has a time complexity of O(n^2), meaning that its running time grows quadratically with the input size.\n",
      "\n",
      "Let's consider the bubble sort algorithm and analyze its time complexity using limits. The bubble sort algorithm works by repeatedly swapping adjacent elements if they are in the wrong order. This process continues until the list is sorted.\n",
      "\n",
      "To analyze the time complexity, we can define a function T(n) that represents the number of comparisons performed by the algorithm for a list of size n. We can then take the limit as n approaches infinity to determine the growth rate of T(n).\n",
      "\n",
      "For the bubble sort algorithm, the number of comparisons can be approximated by the formula T(n) = (n-1) + (n-2) + ... + 1. This is an arithmetic series, and its sum can be calculated using the formula n(n-1)/2.\n",
      "\n",
      "Taking the limit of T(n) as n approaches infinity, we have:\n",
      "\n",
      "$$\\lim_{n \\to \\infty} \\frac{n(n-1)}{2}$$\n",
      "\n",
      "Simplifying, we get:\n",
      "\n",
      "$$\\lim_{n \\to \\infty} \\frac{n^2 - n}{2}$$\n",
      "\n",
      "The dominant term in the numerator is n^2, so we can ignore the -n term. Taking the limit, we find that the time complexity of the bubble sort algorithm is O(n^2).\n",
      "\n",
      "## Exercise\n",
      "Analyze the time complexity of the insertion sort algorithm using limits. The insertion sort algorithm works by repeatedly inserting an element into its correct position in a sorted subarray.\n",
      "\n",
      "### Solution\n",
      "To analyze the time complexity of the insertion sort algorithm, we can define a function T(n) that represents the number of comparisons performed by the algorithm for a list of size n. We can then take the limit as n approaches infinity to determine the growth rate of T(n).\n",
      "\n",
      "For the insertion sort algorithm, the number of comparisons can be approximated by the formula T(n) = 1 + 2 + ... + (n-1). This is also an arithmetic series, and its sum can be calculated using the formula n(n-1)/2.\n",
      "\n",
      "Taking the limit of T(n) as n approaches infinity, we have:\n",
      "\n",
      "$$\\lim_{n \\to \\infty} \\frac{n(n-1)}{2}$$\n",
      "\n",
      "Simplifying, we get:\n",
      "\n",
      "$$\\lim_{n \\to \\infty} \\frac{n^2 - n}{2}$$\n",
      "\n",
      "The dominant term in the numerator is n^2, so we can ignore the -n term. Taking the limit, we find that the time complexity of the insertion sort algorithm is O(n^2).\n",
      "\n",
      "# Techniques for computing integrals in computer science\n",
      "\n",
      "Integrals are an essential concept in calculus that allow us to calculate the total accumulation of a quantity over a given interval. In computer science, integrals are used in various applications, such as analyzing the performance of algorithms, solving optimization problems, and modeling real-world phenomena.\n",
      "\n",
      "There are several techniques for computing integrals, each suited for different types of functions and problem scenarios. In this section, we will explore some of the commonly used techniques and their applications in computer science.\n",
      "\n",
      "One of the fundamental techniques for computing integrals is the definite integral. The definite integral calculates the area under a curve between two specified limits. It is denoted by the symbol $$\\int_a^b f(x) dx$$, where a and b are the lower and upper limits of integration, and f(x) is the function being integrated.\n",
      "\n",
      "To compute the definite integral, we can use various methods, such as the Riemann sum, the trapezoidal rule, and Simpson's rule. These methods approximate the area under the curve by dividing it into smaller segments and summing the areas of these segments.\n",
      "\n",
      "Let's consider an example to illustrate the computation of a definite integral. Suppose we want to calculate the area under the curve of the function f(x) = x^2 between x = 0 and x = 1.\n",
      "\n",
      "Using the Riemann sum method, we can divide the interval [0, 1] into n subintervals of equal width. The width of each subinterval is given by Δx = (b - a) / n, where a = 0 and b = 1.\n",
      "\n",
      "The Riemann sum is then given by the sum of the areas of the rectangles formed by the function values at the left endpoints of each subinterval. The area of each rectangle is given by Δx * f(x_i), where x_i is the left endpoint of the i-th subinterval.\n",
      "\n",
      "By summing the areas of all the rectangles, we can approximate the area under the curve. As we increase the number of subintervals (i.e., take the limit as n approaches infinity), the approximation becomes more accurate.\n",
      "\n",
      "## Exercise\n",
      "Compute the definite integral of the function f(x) = 2x + 3 between x = 1 and x = 4 using the trapezoidal rule.\n",
      "\n",
      "### Solution\n",
      "To compute the definite integral using the trapezoidal rule, we can divide the interval [1, 4] into n subintervals of equal width. The width of each subinterval is given by Δx = (b - a) / n, where a = 1 and b = 4.\n",
      "\n",
      "The trapezoidal rule approximates the area under the curve by summing the areas of trapezoids formed by the function values at the endpoints of each subinterval. The area of each trapezoid is given by (Δx / 2) * (f(x_i) + f(x_{i+1})), where x_i and x_{i+1} are the endpoints of the i-th subinterval.\n",
      "\n",
      "By summing the areas of all the trapezoids, we can approximate the area under the curve. As we increase the number of subintervals (i.e., take the limit as n approaches infinity), the approximation becomes more accurate.\n",
      "\n",
      "# The fundamental theorem of calculus and its applications\n",
      "\n",
      "The fundamental theorem of calculus is a fundamental result in calculus that establishes the connection between differentiation and integration. It states that if a function f(x) is continuous on an interval [a, b] and F(x) is an antiderivative of f(x) on that interval, then the definite integral of f(x) from a to b is equal to the difference in the values of F(x) at the endpoints of the interval.\n",
      "\n",
      "Mathematically, the fundamental theorem of calculus can be stated as follows:\n",
      "\n",
      "$$\\int_a^b f(x) dx = F(b) - F(a)$$\n",
      "\n",
      "where F(x) is an antiderivative of f(x).\n",
      "\n",
      "The fundamental theorem of calculus has many applications in computer science. It allows us to compute definite integrals by finding antiderivatives of functions, which can be useful in solving optimization problems, analyzing algorithms, and modeling real-world phenomena.\n",
      "\n",
      "One important application of the fundamental theorem of calculus is in finding the area under a curve. By computing the definite integral of a function over a given interval, we can determine the area enclosed by the curve and the x-axis.\n",
      "\n",
      "Another application is in solving optimization problems. Optimization problems involve finding the maximum or minimum value of a function over a given interval. By using the fundamental theorem of calculus, we can find the critical points of the function and determine whether they correspond to maximum or minimum values.\n",
      "\n",
      "The fundamental theorem of calculus also plays a role in numerical integration methods, which are used to approximate definite integrals when an antiderivative cannot be found analytically. These methods divide the interval into smaller segments and approximate the area under the curve using techniques such as the trapezoidal rule or Simpson's rule.\n",
      "\n",
      "Let's consider an example to illustrate the application of the fundamental theorem of calculus. Suppose we have a function f(x) = 2x + 3 and we want to compute the definite integral of f(x) from x = 1 to x = 4.\n",
      "\n",
      "First, we need to find an antiderivative of f(x). In this case, an antiderivative of f(x) is F(x) = x^2 + 3x.\n",
      "\n",
      "Using the fundamental theorem of calculus, we can compute the definite integral as follows:\n",
      "\n",
      "$$\\int_1^4 (2x + 3) dx = F(4) - F(1)$$\n",
      "$$= (4^2 + 3*4) - (1^2 + 3*1)$$\n",
      "$$= 16 + 12 - 1 - 3$$\n",
      "$$= 24$$\n",
      "\n",
      "Therefore, the definite integral of f(x) from x = 1 to x = 4 is equal to 24.\n",
      "\n",
      "## Exercise\n",
      "Compute the definite integral of the function f(x) = 3x^2 + 2x - 1 from x = -2 to x = 2 using the fundamental theorem of calculus.\n",
      "\n",
      "### Solution\n",
      "To compute the definite integral using the fundamental theorem of calculus, we need to find an antiderivative of the function f(x). In this case, an antiderivative of f(x) is F(x) = x^3 + x^2 - x.\n",
      "\n",
      "Using the fundamental theorem of calculus, we can compute the definite integral as follows:\n",
      "\n",
      "$$\\int_{-2}^2 (3x^2 + 2x - 1) dx = F(2) - F(-2)$$\n",
      "$$= (2^3 + 2^2 - 2) - ((-2)^3 + (-2)^2 - (-2))$$\n",
      "$$= 8 + 4 - 2 - (-8 + 4 + 2)$$\n",
      "$$= 22$$\n",
      "\n",
      "Therefore, the definite integral of f(x) from x = -2 to x = 2 is equal to 22.\n",
      "\n",
      "# Optimization problems and their relation to integrals\n",
      "\n",
      "Optimization problems are a common topic in computer science and involve finding the maximum or minimum value of a function over a given interval or set of constraints. These problems can be solved using techniques from calculus, specifically by finding the critical points of the function.\n",
      "\n",
      "The relationship between optimization problems and integrals comes from the fact that the maximum or minimum value of a function often occurs at the points where the derivative is equal to zero. These points are known as critical points and can be found by setting the derivative of the function equal to zero and solving for the variable.\n",
      "\n",
      "Once the critical points are found, we can use the fundamental theorem of calculus to determine whether they correspond to maximum or minimum values. If the second derivative of the function is positive at a critical point, then it is a minimum value. If the second derivative is negative, then it is a maximum value.\n",
      "\n",
      "To solve optimization problems using integrals, we first need to define the function that represents the quantity we want to optimize. This function can be a mathematical model of a real-world problem or a function that represents the performance of an algorithm.\n",
      "\n",
      "Next, we find the derivative of the function with respect to the variable we want to optimize. This derivative represents the rate of change of the function and can help us identify the critical points.\n",
      "\n",
      "Once we have the critical points, we evaluate the function at these points to determine the maximum or minimum value. This evaluation is done by computing the definite integral of the function over the interval defined by the critical points.\n",
      "\n",
      "Let's consider an example to illustrate the relationship between optimization problems and integrals. Suppose we want to find the maximum area of a rectangle with a fixed perimeter of 20 units.\n",
      "\n",
      "To solve this problem, we first need to define the function that represents the area of the rectangle. Let's say the length of the rectangle is x units and the width is y units. The area function is then given by A(x, y) = xy.\n",
      "\n",
      "Next, we need to find the derivative of the area function with respect to one of the variables, let's say x. The derivative is given by dA/dx = y.\n",
      "\n",
      "To find the critical points, we set the derivative equal to zero and solve for x. In this case, y = 0, which means that the width of the rectangle is zero. This is not a valid solution, so we can ignore it.\n",
      "\n",
      "Therefore, there are no critical points and the maximum area of the rectangle occurs at the endpoints of the interval defined by the perimeter. In this case, the length of the rectangle is 10 units and the width is 0 units, resulting in an area of 0.\n",
      "\n",
      "## Exercise\n",
      "Consider the function f(x) = x^2 - 4x + 3. Find the maximum or minimum value of this function over the interval [0, 4] using the fundamental theorem of calculus.\n",
      "\n",
      "### Solution\n",
      "To find the maximum or minimum value of the function, we first need to find the critical points. This can be done by finding the derivative of the function and setting it equal to zero.\n",
      "\n",
      "The derivative of f(x) is given by f'(x) = 2x - 4.\n",
      "\n",
      "Setting f'(x) equal to zero, we have 2x - 4 = 0.\n",
      "\n",
      "Solving for x, we get x = 2.\n",
      "\n",
      "Therefore, the critical point is x = 2.\n",
      "\n",
      "To determine whether this critical point corresponds to a maximum or minimum value, we need to evaluate the second derivative of the function at x = 2.\n",
      "\n",
      "The second derivative of f(x) is given by f''(x) = 2.\n",
      "\n",
      "Since the second derivative is positive, the critical point x = 2 corresponds to a minimum value.\n",
      "\n",
      "To find the maximum or minimum value of the function over the interval [0, 4], we evaluate the function at the endpoints and the critical point.\n",
      "\n",
      "f(0) = (0)^2 - 4(0) + 3 = 3\n",
      "f(4) = (4)^2 - 4(4) + 3 = 3\n",
      "f(2) = (2)^2 - 4(2) + 3 = -1\n",
      "\n",
      "Therefore, the minimum value of the function over the interval [0, 4] is -1.\n",
      "\n",
      "# Numerical integration methods and their implementation in algorithms\n",
      "\n",
      "In some cases, it may not be possible to find an exact solution for an integral using traditional methods. This is where numerical integration methods come in handy. Numerical integration methods allow us to approximate the value of an integral by dividing the interval into smaller subintervals and using numerical techniques to estimate the area under the curve.\n",
      "\n",
      "One commonly used numerical integration method is the trapezoidal rule. The trapezoidal rule approximates the area under the curve by dividing the interval into trapezoids and summing up the areas of these trapezoids. The more trapezoids we use, the closer our approximation will be to the actual value of the integral.\n",
      "\n",
      "Another numerical integration method is Simpson's rule. Simpson's rule approximates the area under the curve by fitting a parabola to three consecutive points on the curve and calculating the area under this parabola. By using more points and fitting more parabolas, we can improve the accuracy of our approximation.\n",
      "\n",
      "To implement these numerical integration methods in algorithms, we need to define the function that we want to integrate and specify the interval over which we want to integrate. We also need to determine the number of subintervals or points that we want to use in our approximation.\n",
      "\n",
      "Once we have these parameters, we can use a loop or recursion to calculate the areas of the subintervals or the parabolas and sum them up to get the final approximation of the integral.\n",
      "\n",
      "It's important to note that numerical integration methods are not always exact and can introduce some error. The accuracy of the approximation depends on the number of subintervals or points used and the smoothness of the function being integrated.\n",
      "\n",
      "Let's consider an example to illustrate the implementation of numerical integration methods. Suppose we want to approximate the value of the integral of the function f(x) = x^2 from 0 to 1 using the trapezoidal rule.\n",
      "\n",
      "First, we need to divide the interval [0, 1] into smaller subintervals. Let's say we want to use 4 subintervals.\n",
      "\n",
      "Next, we calculate the width of each subinterval, which is given by (b - a) / n, where b is the upper limit of the interval, a is the lower limit of the interval, and n is the number of subintervals. In this case, the width is (1 - 0) / 4 = 0.25.\n",
      "\n",
      "Now, we can calculate the areas of the trapezoids. The area of each trapezoid is given by (h / 2) * (f(x_i) + f(x_{i+1})), where h is the width of the subinterval, f(x_i) is the value of the function at the lower limit of the subinterval, and f(x_{i+1}) is the value of the function at the upper limit of the subinterval.\n",
      "\n",
      "Using this formula, we can calculate the areas of the 4 trapezoids and sum them up to get the approximation of the integral.\n",
      "\n",
      "## Exercise\n",
      "Approximate the value of the integral of the function f(x) = 2x^3 + 3x^2 - 4x + 1 from -1 to 1 using Simpson's rule with 6 points.\n",
      "\n",
      "### Solution\n",
      "To approximate the value of the integral using Simpson's rule, we first need to divide the interval [-1, 1] into smaller subintervals. Let's say we want to use 6 points, which means we will have 5 subintervals.\n",
      "\n",
      "Next, we calculate the width of each subinterval, which is given by (b - a) / n, where b is the upper limit of the interval, a is the lower limit of the interval, and n is the number of subintervals. In this case, the width is (1 - (-1)) / 5 = 0.4.\n",
      "\n",
      "Now, we can calculate the areas of the parabolas. The area of each parabola is given by (h / 3) * (f(x_i) + 4f(x_{i+1}) + f(x_{i+2})), where h is the width of the subinterval, f(x_i) is the value of the function at the lower limit of the subinterval, f(x_{i+1}) is the value of the function at the midpoint of the subinterval, and f(x_{i+2}) is the value of the function at the upper limit of the subinterval.\n",
      "\n",
      "Using this formula, we can calculate the areas of the 5 parabolas and sum them up to get the approximation of the integral.\n",
      "\n",
      "# The use of integrals in probability and statistics\n",
      "\n",
      "One of the main applications of integrals in probability is calculating probabilities of continuous random variables. Continuous random variables can take on any value within a certain range, and their probability distribution is described by a probability density function (PDF). The probability of a continuous random variable falling within a certain interval is given by the integral of the PDF over that interval.\n",
      "\n",
      "For example, let's consider a continuous random variable X with the following PDF:\n",
      "\n",
      "$$\n",
      "f(x) = \\begin{cases} \n",
      "      2x & 0 \\leq x \\leq 1 \\\\\n",
      "      0 & \\text{otherwise}\n",
      "   \\end{cases}\n",
      "$$\n",
      "\n",
      "To calculate the probability that X falls within the interval [0.2, 0.6], we need to integrate the PDF over that interval:\n",
      "\n",
      "$$\n",
      "P(0.2 \\leq X \\leq 0.6) = \\int_{0.2}^{0.6} 2x \\, dx\n",
      "$$\n",
      "\n",
      "By evaluating this integral, we can find the probability of X falling within the specified interval.\n",
      "\n",
      "Let's calculate the probability that X falls within the interval [0.2, 0.6] using the given PDF:\n",
      "\n",
      "$$\n",
      "P(0.2 \\leq X \\leq 0.6) = \\int_{0.2}^{0.6} 2x \\, dx\n",
      "$$\n",
      "\n",
      "To evaluate this integral, we can use the power rule of integration:\n",
      "\n",
      "$$\n",
      "\\int x^n \\, dx = \\frac{x^{n+1}}{n+1} + C\n",
      "$$\n",
      "\n",
      "Applying this rule to our integral, we get:\n",
      "\n",
      "$$\n",
      "P(0.2 \\leq X \\leq 0.6) = \\left[ x^2 \\right]_{0.2}^{0.6} = 0.6^2 - 0.2^2 = 0.36 - 0.04 = 0.32\n",
      "$$\n",
      "\n",
      "So the probability that X falls within the interval [0.2, 0.6] is 0.32.\n",
      "\n",
      "## Exercise\n",
      "Consider a continuous random variable Y with the following PDF:\n",
      "\n",
      "$$\n",
      "f(y) = \\begin{cases} \n",
      "      3y^2 & 0 \\leq y \\leq 1 \\\\\n",
      "      0 & \\text{otherwise}\n",
      "   \\end{cases}\n",
      "$$\n",
      "\n",
      "Calculate the probability that Y falls within the interval [0.3, 0.7].\n",
      "\n",
      "### Solution\n",
      "To calculate the probability that Y falls within the interval [0.3, 0.7], we need to integrate the PDF over that interval:\n",
      "\n",
      "$$\n",
      "P(0.3 \\leq Y \\leq 0.7) = \\int_{0.3}^{0.7} 3y^2 \\, dy\n",
      "$$\n",
      "\n",
      "To evaluate this integral, we can use the power rule of integration:\n",
      "\n",
      "$$\n",
      "\\int x^n \\, dx = \\frac{x^{n+1}}{n+1} + C\n",
      "$$\n",
      "\n",
      "Applying this rule to our integral, we get:\n",
      "\n",
      "$$\n",
      "P(0.3 \\leq Y \\leq 0.7) = \\left[ y^3 \\right]_{0.3}^{0.7} = 0.7^3 - 0.3^3 = 0.343 - 0.027 = 0.316\n",
      "$$\n",
      "\n",
      "So the probability that Y falls within the interval [0.3, 0.7] is 0.316.\n",
      "\n",
      "# Integration in machine learning algorithms\n",
      "\n",
      "Integration plays a crucial role in machine learning algorithms. Many machine learning algorithms involve optimizing a cost function, which is typically defined as the difference between the predicted output of the algorithm and the true output. Integration can be used to calculate the area under the cost function curve, which represents the total error of the algorithm.\n",
      "\n",
      "One common machine learning algorithm that uses integration is linear regression. Linear regression aims to find the best-fitting line that minimizes the sum of the squared differences between the predicted and true outputs. This sum of squared differences can be calculated using integration.\n",
      "\n",
      "To calculate the sum of squared differences, we first need to define the cost function. In the case of linear regression, the cost function is typically defined as the mean squared error (MSE). The MSE is the average of the squared differences between the predicted and true outputs.\n",
      "\n",
      "Once we have the cost function, we can calculate the area under the curve by integrating the cost function over the range of possible inputs. This gives us a measure of the total error of the algorithm.\n",
      "\n",
      "Let's consider a simple linear regression problem where we want to predict a person's weight based on their height. We have a dataset of height-weight pairs, and we want to find the best-fitting line that minimizes the sum of squared differences between the predicted and true weights.\n",
      "\n",
      "We can define the cost function as the mean squared error (MSE):\n",
      "\n",
      "$$\n",
      "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
      "$$\n",
      "\n",
      "where $y_i$ is the true weight, $\\hat{y}_i$ is the predicted weight, and $n$ is the number of data points.\n",
      "\n",
      "To calculate the total error of the algorithm, we need to integrate the cost function over the range of possible inputs (heights). This gives us a measure of how well the algorithm is performing.\n",
      "\n",
      "## Exercise\n",
      "Consider a linear regression problem where we want to predict a person's salary based on their years of experience. We have a dataset of experience-salary pairs, and we want to find the best-fitting line that minimizes the sum of squared differences between the predicted and true salaries.\n",
      "\n",
      "Define the cost function as the mean squared error (MSE):\n",
      "\n",
      "$$\n",
      "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
      "$$\n",
      "\n",
      "where $y_i$ is the true salary, $\\hat{y}_i$ is the predicted salary, and $n$ is the number of data points.\n",
      "\n",
      "Calculate the total error of the algorithm by integrating the cost function over the range of possible inputs (years of experience).\n",
      "\n",
      "### Solution\n",
      "To calculate the total error of the algorithm, we need to integrate the cost function over the range of possible inputs (years of experience). This gives us a measure of how well the algorithm is performing.\n",
      "\n",
      "The specific integration will depend on the form of the cost function and the range of possible inputs. In this case, we can assume that the cost function is a quadratic function of the form $ax^2 + bx + c$, where $x$ represents years of experience.\n",
      "\n",
      "To integrate this quadratic function, we can use the power rule of integration:\n",
      "\n",
      "$$\n",
      "\\int x^n \\, dx = \\frac{x^{n+1}}{n+1} + C\n",
      "$$\n",
      "\n",
      "Applying this rule to our cost function, we get:\n",
      "\n",
      "$$\n",
      "\\text{Total Error} = \\int_{a}^{b} (ax^2 + bx + c) \\, dx\n",
      "$$\n",
      "\n",
      "By evaluating this integral over the range of possible inputs, we can calculate the total error of the algorithm.\n",
      "\n",
      "# Applications of calculus in data science\n",
      "\n",
      "One important application of calculus in data science is optimization. Optimization involves finding the values of variables that minimize or maximize a given function. Calculus provides the tools to find these optimal values by analyzing the properties of the function.\n",
      "\n",
      "Another application of calculus in data science is regression analysis. Regression analysis is used to model the relationship between a dependent variable and one or more independent variables. Calculus is used to estimate the parameters of the regression model and make predictions based on the model.\n",
      "\n",
      "Calculus is also used in data science for data smoothing and interpolation. Data smoothing involves removing noise from a data set to reveal underlying trends and patterns. Interpolation involves estimating the value of a data point based on its neighboring data points. Calculus provides the mathematical techniques to perform these operations.\n",
      "\n",
      "Furthermore, calculus is used in data science for probability and statistics. Calculus is used to calculate probabilities, expected values, and other important quantities in these fields. It is also used to derive the formulas for statistical tests and estimators.\n",
      "\n",
      "Let's consider an example to illustrate the application of calculus in data science. Suppose we have a data set of housing prices and we want to build a regression model to predict the price of a house based on its size and number of bedrooms.\n",
      "\n",
      "We can use calculus to estimate the parameters of the regression model. By minimizing the sum of squared differences between the predicted and true prices, we can find the values of the parameters that best fit the data.\n",
      "\n",
      "Once we have the regression model, we can use calculus to make predictions based on the model. By plugging in the values of the independent variables into the regression equation, we can estimate the price of a house.\n",
      "\n",
      "## Exercise\n",
      "Consider a data set of stock prices and you want to build a regression model to predict the price of a stock based on its trading volume and the performance of the overall market.\n",
      "\n",
      "Use calculus to estimate the parameters of the regression model. By minimizing the sum of squared differences between the predicted and true prices, find the values of the parameters that best fit the data.\n",
      "\n",
      "Make predictions based on the regression model by plugging in the values of the independent variables into the regression equation.\n",
      "\n",
      "### Solution\n",
      "To estimate the parameters of the regression model, we need to minimize the sum of squared differences between the predicted and true prices. This can be done using calculus.\n",
      "\n",
      "The specific optimization algorithm will depend on the form of the regression model and the data set. One common algorithm is the least squares method, which involves minimizing the sum of squared differences.\n",
      "\n",
      "Once we have the regression model, we can make predictions by plugging in the values of the independent variables into the regression equation. The specific form of the regression equation will depend on the form of the regression model.\n",
      "\n",
      "# The history of calculus and its impact on computer science\n",
      "\n",
      "Calculus, as a branch of mathematics, has a rich history that dates back to ancient times. The foundations of calculus were laid by ancient Greek mathematicians such as Archimedes and Eudoxus. However, it was not until the 17th century that calculus as we know it today began to take shape.\n",
      "\n",
      "The development of calculus is often attributed to two mathematicians: Isaac Newton and Gottfried Wilhelm Leibniz. Newton developed the branch of calculus known as differential calculus, which focuses on rates of change and slopes of curves. Leibniz, on the other hand, developed integral calculus, which deals with the accumulation of quantities and the calculation of areas.\n",
      "\n",
      "The invention of calculus revolutionized mathematics and had a profound impact on various fields, including computer science. Calculus provides the mathematical tools to describe and analyze continuous change, which is essential in many computer science applications.\n",
      "\n",
      "One major area where calculus is used in computer science is in algorithms and computational complexity. Calculus helps in analyzing the efficiency and performance of algorithms by quantifying their time and space complexity. It allows us to understand how the runtime of an algorithm changes as the input size grows, and helps in designing more efficient algorithms.\n",
      "\n",
      "For example, in machine learning, calculus is used in the optimization of models. By finding the minimum or maximum of a cost function using calculus, we can adjust the parameters of a model to make it more accurate and efficient.\n",
      "\n",
      "In computer graphics, calculus is used to model and render 3D objects and animations. Calculus helps in calculating the slopes and rates of change of curves and surfaces, allowing for realistic and smooth rendering of objects.\n",
      "\n",
      "Calculus also plays a crucial role in data analysis and visualization. It enables us to analyze and interpret data by calculating derivatives and integrals, which provide insights into the behavior and trends of the data. Calculus is used in statistical analysis, curve fitting, and data smoothing techniques.\n",
      "\n",
      "Furthermore, calculus is the foundation of many other branches of mathematics that are essential in computer science, such as linear algebra and probability theory. These mathematical concepts are used in various areas of computer science, including machine learning, cryptography, and network analysis.\n",
      "\n",
      "## Exercise\n",
      "Consider a scenario where you are analyzing a large dataset of user behavior on a website. You want to identify patterns and trends in the data to improve the user experience. How can calculus be applied in this scenario?\n",
      "\n",
      "### Solution\n",
      "In this scenario, calculus can be applied in several ways. First, calculus can be used to calculate derivatives of the data to determine the rates of change and identify critical points. This can help in identifying sudden changes or anomalies in user behavior.\n",
      "\n",
      "Second, calculus can be used to calculate integrals of the data to analyze the overall trends and patterns. Integrals can provide insights into the total number of interactions, the distribution of user behavior, and the overall performance of the website.\n",
      "\n",
      "Finally, calculus can be used in statistical analysis to model and predict user behavior. By fitting curves to the data using regression analysis, calculus can help in understanding the relationships between different variables and making predictions based on the data.\n",
      "\n",
      "# Future advancements and developments in calculus and computer science\n",
      "\n",
      "The field of calculus and computer science is constantly evolving, and there are several exciting advancements and developments on the horizon. These advancements have the potential to further enhance the applications of calculus in computer science and drive innovation in the field.\n",
      "\n",
      "One area of future advancement is the integration of calculus with artificial intelligence and machine learning. As AI and machine learning algorithms become more sophisticated, the use of calculus can help in optimizing these algorithms and improving their performance. Calculus can be used to analyze the gradients and rates of change in neural networks, leading to more efficient and accurate models.\n",
      "\n",
      "Another area of future development is the application of calculus in quantum computing. Quantum computing is an emerging field that utilizes the principles of quantum mechanics to perform complex computations. Calculus can play a crucial role in developing algorithms and analyzing the behavior of quantum systems, paving the way for advancements in quantum computing.\n",
      "\n",
      "Additionally, the integration of calculus with big data analytics is an area of future growth. As the amount of data generated continues to increase exponentially, the need for efficient data analysis techniques becomes more important. Calculus can provide the mathematical tools to analyze and interpret large datasets, enabling the extraction of valuable insights and patterns.\n",
      "\n",
      "For example, in the field of autonomous vehicles, calculus can be used to develop algorithms for path planning and obstacle avoidance. By analyzing the rates of change and slopes of curves, autonomous vehicles can navigate complex environments and make real-time decisions.\n",
      "\n",
      "In the field of cybersecurity, calculus can be applied to analyze network traffic and detect anomalies. By calculating derivatives and integrals of network data, calculus can help in identifying patterns of malicious activity and improving the security of computer systems.\n",
      "\n",
      "In conclusion, the future of calculus and its impact on computer science is promising. With advancements in AI, quantum computing, and big data analytics, calculus will continue to play a crucial role in driving innovation and solving complex problems in computer science. By understanding the principles of calculus and its practical applications, students can prepare themselves for the exciting advancements that lie ahead.\n",
      "\n",
      "## Exercise\n",
      "Think about a specific area of computer science that interests you. How do you think calculus could be applied in that area in the future? Describe a potential application of calculus and explain how it could benefit the field.\n",
      "\n",
      "### Solution\n",
      "One area of computer science that interests me is natural language processing (NLP). In the future, calculus could be applied in NLP to improve language understanding and translation algorithms. By analyzing the rates of change and slopes of language patterns, calculus can help in developing more accurate and efficient NLP models. This could benefit the field by enabling better machine translation, sentiment analysis, and language generation algorithms, leading to advancements in areas such as automated customer support and language learning applications.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_name, split=\"train[0:10000]\")\n",
    "print(dataset[\"markdown\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838dcea1-8af3-4d94-8516-af73c574a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True\n",
    "#tokenizer.add_bos_token, tokenizer.add_eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dce31cf-c0f0-43bb-a8a4-d2ec898e5332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf50e922161477daf238150975cd66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(256008, 4096, padding_idx=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load base model(llama-2-7b-hf)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit= True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.float16,\n",
    "    bnb_4bit_use_double_quant= False,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
    "model.config.pretraining_tp = 1\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82576ba-ca2f-475b-843b-8a9e6028841a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGLMForCausalLM(\n",
      "  (model): XGLMModel(\n",
      "    (embed_tokens): Embedding(256008, 4096, padding_idx=1)\n",
      "    (embed_positions): XGLMSinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x XGLMDecoderLayer(\n",
      "        (self_attn): XGLMAttention(\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
      "          (out_proj): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
      "        )\n",
      "        (activation_fn): GELUActivation()\n",
      "        (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear4bit(in_features=4096, out_features=16384, bias=True)\n",
      "        (fc2): Linear4bit(in_features=16384, out_features=4096, bias=True)\n",
      "        (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=256008, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589937b3-ae9e-4901-9c9b-a4764637b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mryuinw123\u001b[0m (\u001b[33mllm-courseville\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ryu/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ryu\\Desktop\\llm\\finetunellm-preview\\wandb\\run-20231113_014208-w86hwl8k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/llm-courseville/Fine%20tuning%20llama-2-7B/runs/w86hwl8k' target=\"_blank\">expert-field-14</a></strong> to <a href='https://wandb.ai/llm-courseville/Fine%20tuning%20llama-2-7B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/llm-courseville/Fine%20tuning%20llama-2-7B' target=\"_blank\">https://wandb.ai/llm-courseville/Fine%20tuning%20llama-2-7B</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/llm-courseville/Fine%20tuning%20llama-2-7B/runs/w86hwl8k' target=\"_blank\">https://wandb.ai/llm-courseville/Fine%20tuning%20llama-2-7B/runs/w86hwl8k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login(key=\"e52be3b876f1591b2e7c14126ecef4387c68d4aa\")\n",
    "run = wandb.init(project='Fine tuning llama-2-7B', job_type=\"training\", anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fdf0871-bf95-4605-9cdc-6ef59b1f5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha= 8,\n",
    "    lora_dropout= 0.1,\n",
    "    r= 16,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b8d363c-b5a4-463f-8fe3-16d899dcdc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir= \"./results\",\n",
    "    num_train_epochs= 1,\n",
    "    per_device_train_batch_size= 4,\n",
    "    gradient_accumulation_steps= 2,\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    save_steps= 1000,\n",
    "    logging_steps= 30,\n",
    "    learning_rate= 2e-4,\n",
    "    weight_decay= 0.001,\n",
    "    fp16= False,\n",
    "    bf16= False,\n",
    "    max_grad_norm= 0.3,\n",
    "    max_steps= -1,\n",
    "    warmup_ratio= 0.3,\n",
    "    group_by_length= True,\n",
    "    lr_scheduler_type= \"linear\",\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e6334bf-102c-49b2-8a75-fd0b52170221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryu\\.conda\\envs\\llm\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:194: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length= None,\n",
    "    dataset_text_field=\"markdown\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing= False,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62a78898-b663-45df-aec9-ffa85f9f686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using 8-bit optimizers with a version of `bitsandbytes` < 0.41.1. It is recommended to update your version as a major bug has been fixed in 8-bit optimizers.\n",
      "You're using a XGLMTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "C:\\Users\\ryu\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 6:56:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.515600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.413400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.326300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.196500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.189900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.174900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.133100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.092600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.090800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.078600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.072800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.079900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.061400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.063400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.045700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.987700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.968100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.998800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.996200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.989200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.976700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.937300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.982600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.941700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.962700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.939400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryu\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=1.0773604873657228, metrics={'train_runtime': 25006.7262, 'train_samples_per_second': 0.4, 'train_steps_per_second': 0.05, 'total_flos': 3.9670247325696e+17, 'train_loss': 1.0773604873657228, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40a63011-c7b1-4bac-ba2d-38799ea4658a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁▂▃▃▄▄▅▅▆▇▇███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>█▇▆▅▄▄▄▃▃▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>1250</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.9394</td></tr><tr><td>train/total_flos</td><td>3.9670247325696e+17</td></tr><tr><td>train/train_loss</td><td>1.07736</td></tr><tr><td>train/train_runtime</td><td>25006.7262</td></tr><tr><td>train/train_samples_per_second</td><td>0.4</td></tr><tr><td>train/train_steps_per_second</td><td>0.05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-field-14</strong> at: <a href='https://wandb.ai/llm-courseville/Fine%20tuning%20llama-2-7B/runs/w86hwl8k' target=\"_blank\">https://wandb.ai/llm-courseville/Fine%20tuning%20llama-2-7B/runs/w86hwl8k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231113_014208-w86hwl8k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "XGLMForCausalLM(\n",
       "  (model): XGLMModel(\n",
       "    (embed_tokens): Embedding(256008, 4096, padding_idx=1)\n",
       "    (embed_positions): XGLMSinusoidalPositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x XGLMDecoderLayer(\n",
       "        (self_attn): XGLMAttention(\n",
       "          (k_proj): Linear4bit(\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (v_proj): Linear4bit(\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (q_proj): Linear4bit(\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
       "          )\n",
       "          (out_proj): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear4bit(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc2): Linear4bit(in_features=16384, out_features=4096, bias=True)\n",
       "        (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=256008, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.save_pretrained(new_model)\n",
    "wandb.finish()\n",
    "model.config.use_cache = True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f70b77df-d3c9-4953-9544-4f1fabcc6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8be1ad93-9553-4496-bd2c-5a1d3c3d9369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream(user_prompt):\n",
    "    runtimeFlag = \"cuda:0\"\n",
    "    system_prompt = 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n'\n",
    "    B_INST, E_INST = \"### Instruction:\\n\", \"### Response:\\n\"\n",
    "\n",
    "    prompt = f\"{system_prompt}{B_INST}{user_prompt.strip()}\\n\\n{E_INST}\"\n",
    "\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(runtimeFlag)\n",
    "\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "    # Despite returning the usual output, the streamer will also print the generated text to stdout.\n",
    "    _ = model.generate(**inputs, streamer=streamer, max_new_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3302f25-bc31-43bb-8f7e-d4b05c8e5078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ### Solution: ### Instruction: Applications of homomorphic encryption in blockchain technology ### Task: Encrypt and decrypt a message using the RSA algorithm. ###\n"
     ]
    }
   ],
   "source": [
    "stream(\"Applications of homomorphic encryption in blockchain technology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebf96a24-5305-49c0-b06e-08ecfefcc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d819c1c-01d1-4cb4-a192-dbe716a9a9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5695e6147a854f94a2175740c8f5da15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, low_cpu_mem_usage=True,\n",
    "    return_dict=True,torch_dtype=torch.float16,\n",
    "    device_map= {\"\": 0})\n",
    "model = PeftModel.from_pretrained(base_model, new_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6bd3d-d1ef-43a0-83ec-ec7aabfe9034",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(new_model)\n",
    "tokenizer.push_to_hub(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a3286ce-fa0d-45dc-b9e3-e136496c5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = \"[MASK]\"\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Creating a dummy input\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "dummy_input = [tokens_tensor, segments_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21fe122f-34c1-4d6c-a366-175c5a5c3619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGLMForCausalLM(\n",
       "  (model): XGLMModel(\n",
       "    (embed_tokens): Embedding(256008, 4096, padding_idx=1)\n",
       "    (embed_positions): XGLMSinusoidalPositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x XGLMDecoderLayer(\n",
       "        (self_attn): XGLMAttention(\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "        (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=256008, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc5db8b-c6d7-4681-bca1-50fa4422c5ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m traced_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtokens_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegments_tensors\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39msave(traced_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraced_bert.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\jit\\_trace.py:798\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    815\u001b[0m ):\n\u001b[0;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\jit\\_trace.py:1065\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1064\u001b[0m     example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[1;32m-> 1065\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m        \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1076\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1508\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1508\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1510\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\models\\xglm\\modeling_xglm.py:749\u001b[0m, in \u001b[0;36mXGLMForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    746\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m--> 749\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    765\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    767\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1508\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1508\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1510\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\transformers\\models\\xglm\\modeling_xglm.py:572\u001b[0m, in \u001b[0;36mXGLMModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    569\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m position_ids\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 572\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_scale\n\u001b[0;32m    574\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_causal_attention_mask(\n\u001b[0;32m    575\u001b[0m     attention_mask, input_shape, inputs_embeds, past_key_values_length\n\u001b[0;32m    576\u001b[0m )\n\u001b[0;32m    578\u001b[0m \u001b[38;5;66;03m# expand encoder attention mask\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1508\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1508\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1510\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\llm\\Lib\\site-packages\\torch\\nn\\functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])\n",
    "torch.jit.save(traced_model, \"traced_bert.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312824d-3984-43a1-b31e-abe7538de83e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
