{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2d9dbd-4b3b-4b6c-a623-3b8872656e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd86469-1ae4-47fd-a30a-d8b6921cd14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4204af01-d497-4040-a17e-2abd2a8d5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre trained model\n",
    "model_name = \"pythainlp/wangchanglm-7.5B-sft-enth\"\n",
    "# Dataset name\n",
    "dataset_name = \"code_search_net\"\n",
    "\n",
    "# Hugging face repository link to save fine-tuned model(Create new repository in huggingface,copy and paste here)\n",
    "new_model = \"ryuinw123/test-finetune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6db092f5-d430-40d4-8de6-858859241a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryu\\.conda\\envs\\llm\\Lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(dataset_name, \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8af5705-1e98-4fd8-810c-ef5ba2d4f683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "    num_rows: 412178\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c4ac559-474a-4724-a67d-63c77b7b1b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def last_rate_limit(self):\n",
      "        \"\"\"\n",
      "        A `dict` of the rate limit information returned in the most recent\n",
      "        response, or `None` if no requests have been made yet.  The `dict`\n",
      "        consists of all headers whose names begin with ``\"RateLimit\"`` (case\n",
      "        insensitive).\n",
      "\n",
      "        The DigitalOcean API specifies the following rate limit headers:\n",
      "\n",
      "        :var string RateLimit-Limit: the number of requests that can be made\n",
      "            per hour\n",
      "        :var string RateLimit-Remaining: the number of requests remaining until\n",
      "            the limit is reached\n",
      "        :var string RateLimit-Reset: the Unix timestamp for the time when the\n",
      "            oldest request will expire from rate limit consideration\n",
      "        \"\"\"\n",
      "        if self.last_response is None:\n",
      "            return None\n",
      "        else:\n",
      "            return {k:v for k,v in iteritems(self.last_response.headers)\n",
      "                        if k.lower().startswith('ratelimit')}\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][123456][\"whole_func_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14bfa3f-dfe4-42aa-b38a-ad525471dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_corpus = [raw_datasets[\"train\"][i: i + 1000][\"whole_func_string\"] for i in range(0, len(raw_datasets[\"train\"]), 1000)]\n",
    "#training_corpus[0][0]\n",
    "context_length = 256\n",
    "def get_training_corpus(threshold=256):\n",
    "    dataset = raw_datasets[\"train\"]\n",
    "    for start_idx in range(0, len(dataset), 1000):\n",
    "        samples = dataset[start_idx : start_idx + 1000]\n",
    "        samples = [sample for sample in samples['whole_func_string'] if len(sample) < threshold]\n",
    "        yield samples\n",
    "training_corpus = get_training_corpus(context_length)\n",
    "#training_corpus = (\n",
    "#    raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "#    for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba8fb75-cc73-4c48-9204-8ff94cbe8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14ddf308-2a47-43d1-8030-960e7fc60160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁def',\n",
       " '▁add',\n",
       " '_',\n",
       " 'number',\n",
       " 's',\n",
       " '(',\n",
       " 'a',\n",
       " ',',\n",
       " '▁b',\n",
       " '):',\n",
       " '▁\"',\n",
       " '\"\"',\n",
       " 'Add',\n",
       " '▁the',\n",
       " '▁two',\n",
       " '▁numbers',\n",
       " '▁`',\n",
       " 'a',\n",
       " '`',\n",
       " '▁and',\n",
       " '▁`',\n",
       " 'b',\n",
       " '`',\n",
       " '.\"',\n",
       " '\"\"',\n",
       " '▁return',\n",
       " '▁a',\n",
       " '▁+',\n",
       " '▁b']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = '''def add_numbers(a, b):\n",
    "    \"\"\"Add the two numbers `a` and `b`.\"\"\"\n",
    "    return a + b'''\n",
    "\n",
    "tokens = old_tokenizer.tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21a7e367-61d7-46ac-9ec8-6de096e6374d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256008\n"
     ]
    }
   ],
   "source": [
    "print(len(old_tokenizer))\n",
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, len(old_tokenizer) + 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c208684d-1231-4815-b78d-34c8369e8a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁def',\n",
       " '▁add',\n",
       " '_numbers(',\n",
       " 'a,',\n",
       " '▁b',\n",
       " '):',\n",
       " '▁\"\"\"Add',\n",
       " '▁the',\n",
       " '▁two',\n",
       " '▁numbers',\n",
       " '▁`a`',\n",
       " '▁and',\n",
       " '▁`b`.',\n",
       " '\"\"\"',\n",
       " '▁return',\n",
       " '▁a',\n",
       " '▁+',\n",
       " '▁b']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tokenizer))\n",
    "tokens = tokenizer.tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "376be1ea-41b4-48dd-b16c-e862bcb21697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0cfbcbd-2832-4b74-b545-d794d0d4c849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfbd85b7-3cc6-47f8-b6f8-6b563b1bfc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "205141d6-61db-4401-88e5-d16e6b9e3b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "752daaf8-afa9-4ab7-b241-529fa8f9becc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28b77dac-9ac2-4b96-9a3b-6e5d6e1d97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0f92fcb-e8de-41b3-b552-dde0b3af4400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 85451, 43028,   190,  8910, 23985,  1299,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2],\n",
       "        [    2,   891,  2962,  3394,   723, 20191,  1410,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"My experiments are going strong!\", \n",
    "           \"I love Llamas\"], \n",
    "          # padding='max_length', \n",
    "          padding='max_length',\n",
    "          max_length=context_length,\n",
    "          return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa95e0d7-8e1b-469b-ac0b-d1894d634450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import glob\n",
    "#file_list = glob.glob(\"./data/train/jsonl/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "066e0ca1-5e3b-461f-ba4d-21a72675207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs = [] # an empty list to store the data frames\n",
    "#for file in file_list:\n",
    "#    data = pd.read_json(file, lines=True) # read data frame from json file\n",
    "#    dfs.append(data) # append the data frame to the list\n",
    "\n",
    "#temp = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30ed7dbf-f6cc-4a8a-94c2-fe9d0feb325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = temp[[\"original_string\" , \"docstring\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "955eddd1-5937-48ae-85e2-8f639532ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = df.head().apply(prompt , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "051ca481-5812-4b8b-bc19-13179588c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "someDf = pd.DataFrame(raw_datasets[\"train\"])\n",
    "someDf_eval = pd.DataFrame(raw_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54b38e09-f518-4a3e-bf0d-2bf0e1bf85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "someDf_eval = pd.DataFrame(raw_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c67a54-e343-4ff9-8629-4c8fc3899f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(row):\n",
    "    return f\"\"\"<s>Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "            Write a response that appropriately completes the request.\\n\\n\n",
    "            ### Instruction:\\n{row[\"func_documentation_string\"]} If coding use python for it \\n\\n \\n\\n### Response:\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7375772-ba66-4a65-9c2e-b42d16ac9a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Below is an instruction that describes a task, paired with an input that provides further context. \\n            Write a response that appropriately completes the request.\\n\\n\\n            ### Instruction:\\nTrains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data. If coding use python for it \\n\\n \\n\\n### Response:\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someDf.head().apply(prompt , axis = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1965df3b-7ccc-4ed3-92b4-74d631ed772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = someDf[[\"func_documentation_string\" , \"whole_func_string\"]]\n",
    "df_eval = someDf_eval[[\"func_documentation_string\" , \"whole_func_string\"]]\n",
    "\n",
    "del(someDf)\n",
    "del(someDf_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73077248-4837-4ea9-907f-a468ff6f86ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func_documentation_string</th>\n",
       "      <th>whole_func_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trains a k-nearest neighbors classifier for fa...</td>\n",
       "      <td>def train(train_dir, model_save_path=None, n_n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recognizes faces in given image using a traine...</td>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shows the face recognition results visually.\\n...</td>\n",
       "      <td>def show_prediction_labels_on_image(img_path, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Convert a dlib 'rect' object to a plain tuple ...</td>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Make sure a tuple in (top, right, bottom, left...</td>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412173</th>\n",
       "      <td>Get shared OTUIDs between all unique combinati...</td>\n",
       "      <td>def shared_otuids(groups):\\n    \"\"\"\\n    Get s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412174</th>\n",
       "      <td>Given a path, the method writes out one file f...</td>\n",
       "      <td>def write_uniques(path, prefix, uniques):\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412175</th>\n",
       "      <td>Parse the records in a FASTA-format file by fi...</td>\n",
       "      <td>def storeFASTA(fastaFNH):\\n    \"\"\"\\n    Parse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412176</th>\n",
       "      <td>Parse the records in a FASTA-format file keepi...</td>\n",
       "      <td>def parseFASTA(fastaFNH):\\n    \"\"\"\\n    Parse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412177</th>\n",
       "      <td>Opens a QIIME mapping file and stores the cont...</td>\n",
       "      <td>def parse_map_file(mapFNH):\\n    \"\"\"\\n    Open...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412178 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                func_documentation_string  \\\n",
       "0       Trains a k-nearest neighbors classifier for fa...   \n",
       "1       Recognizes faces in given image using a traine...   \n",
       "2       Shows the face recognition results visually.\\n...   \n",
       "3       Convert a dlib 'rect' object to a plain tuple ...   \n",
       "4       Make sure a tuple in (top, right, bottom, left...   \n",
       "...                                                   ...   \n",
       "412173  Get shared OTUIDs between all unique combinati...   \n",
       "412174  Given a path, the method writes out one file f...   \n",
       "412175  Parse the records in a FASTA-format file by fi...   \n",
       "412176  Parse the records in a FASTA-format file keepi...   \n",
       "412177  Opens a QIIME mapping file and stores the cont...   \n",
       "\n",
       "                                        whole_func_string  \n",
       "0       def train(train_dir, model_save_path=None, n_n...  \n",
       "1       def predict(X_img_path, knn_clf=None, model_pa...  \n",
       "2       def show_prediction_labels_on_image(img_path, ...  \n",
       "3       def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...  \n",
       "4       def _trim_css_to_bounds(css, image_shape):\\n  ...  \n",
       "...                                                   ...  \n",
       "412173  def shared_otuids(groups):\\n    \"\"\"\\n    Get s...  \n",
       "412174  def write_uniques(path, prefix, uniques):\\n   ...  \n",
       "412175  def storeFASTA(fastaFNH):\\n    \"\"\"\\n    Parse ...  \n",
       "412176  def parseFASTA(fastaFNH):\\n    \"\"\"\\n    Parse ...  \n",
       "412177  def parse_map_file(mapFNH):\\n    \"\"\"\\n    Open...  \n",
       "\n",
       "[412178 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "459768ec-a016-49ae-bd7a-e87dc765df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"input\"] = df.apply(prompt , axis = 1)\n",
    "df_eval[\"input\"] = df_eval.apply(prompt , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64d29a2f-003a-4702-8200-7540aec289e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"output\"] = df[\"whole_func_string\"] + \"</s>\"\n",
    "df_eval[\"output\"] =df_eval[\"whole_func_string\"] + \"</s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ace83acd-c853-4089-ba86-87e6b4c597b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"example\"] = df[\"input\"] + df[\"output\"]\n",
    "df_eval[\"example\"] = df_eval[\"input\"] + df_eval[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ce606ab-bd1a-4af8-9d23-85d8f6f014e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Below is an instruction that describes a task, paired with an input that provides further context. \\n            Write a response that appropriately completes the request.\\n\\n\\n            ### Instruction:\\nRecognizes faces in given image using a trained KNN classifier\\n\\n    :param X_img_path: path to image to be recognized\\n    :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified.\\n    :param model_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf.\\n    :param distance_threshold: (optional) distance threshold for face classification. the larger it is, the more chance\\n           of mis-classifying an unknown person as a known one.\\n    :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...].\\n        For faces of unrecognized persons, the name \\'unknown\\' will be returned. If coding use python for it \\n\\n \\n\\n### Response:\\ndef predict(X_img_path, knn_clf=None, model_path=None, distance_threshold=0.6):\\n    \"\"\"\\n    Recognizes faces in given image using a trained KNN classifier\\n\\n    :param X_img_path: path to image to be recognized\\n    :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified.\\n    :param model_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf.\\n    :param distance_threshold: (optional) distance threshold for face classification. the larger it is, the more chance\\n           of mis-classifying an unknown person as a known one.\\n    :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...].\\n        For faces of unrecognized persons, the name \\'unknown\\' will be returned.\\n    \"\"\"\\n    if not os.path.isfile(X_img_path) or os.path.splitext(X_img_path)[1][1:] not in ALLOWED_EXTENSIONS:\\n        raise Exception(\"Invalid image path: {}\".format(X_img_path))\\n\\n    if knn_clf is None and model_path is None:\\n        raise Exception(\"Must supply knn classifier either thourgh knn_clf or model_path\")\\n\\n    # Load a trained KNN model (if one was passed in)\\n    if knn_clf is None:\\n        with open(model_path, \\'rb\\') as f:\\n            knn_clf = pickle.load(f)\\n\\n    # Load image file and find face locations\\n    X_img = face_recognition.load_image_file(X_img_path)\\n    X_face_locations = face_recognition.face_locations(X_img)\\n\\n    # If no faces are found in the image, return an empty result.\\n    if len(X_face_locations) == 0:\\n        return []\\n\\n    # Find encodings for faces in the test iamge\\n    faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_face_locations)\\n\\n    # Use the KNN model to find the best matches for the test face\\n    closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\\n    are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\\n\\n    # Predict classes and remove classifications that aren\\'t within the threshold\\n    return [(pred, loc) if rec else (\"unknown\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]</s>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"example\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86f7c4bf-f20b-495c-824a-9cf9a0e147ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokenize\"] = df[\"example\"].apply(lambda x : tokenizer(x,padding='max_length',max_length=context_length)[\"input_ids\"])\n",
    "df_eval[\"tokenize\"] = df_eval[\"example\"].apply(lambda x : tokenizer(x,padding='max_length',max_length=context_length)[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1566a28-77ce-4688-839f-e71e2b067b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word_count\"] = df[\"tokenize\"].apply(lambda x : len(x))\n",
    "df_eval[\"word_count\"] = df_eval[\"tokenize\"].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbb7f2a1-6b53-4063-8815-036553693bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"word_count\"] == context_length]\n",
    "df_eval = df_eval[df_eval[\"word_count\"] == context_length]\n",
    "df = df.sample(frac=0.05)\n",
    "df_eval = df_eval.sample(frac=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b592793c-f1d3-4ee0-9da6-ec6a2b71bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"input_ids\"] = df[\"tokenize\"].apply(lambda x : x[:-1])\n",
    "df_eval[\"input_ids\"] = df_eval[\"tokenize\"].apply(lambda x : x[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1382a3a2-fec4-4bb2-b2ca-a8167ee61b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"labels\"] = df[\"tokenize\"].apply(lambda x : x[1:])\n",
    "df_eval[\"labels\"] = df_eval[\"tokenize\"].apply(lambda x : x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3062b64b-4b62-4448-9d09-e6f75bf7e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['func_documentation_string','whole_func_string','example' , 'word_count' , 'tokenize'] , axis = 1)\n",
    "df_eval= df_eval.drop(['func_documentation_string','whole_func_string','example' , 'word_count' , 'tokenize'] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cdea8fe-8517-4866-a8d2-00019ab2987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_dataset = df.to_dict(\"records\")\n",
    "#del df\n",
    "eval_dataset = df_eval.to_dict(\"records\")\n",
    "#del df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9892b1da-859b-4621-9ad8-474b1aa126a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '<s>Below is an instruction that describes a task, paired with an input that provides further context. \\n            Write a response that appropriately completes the request.\\n\\n\\n            ### Instruction:\\nGets the raid level for each logical volume\\n\\n        :returns the set of list of raid levels configured If coding use python for it \\n\\n \\n\\n### Response:\\n',\n",
       " 'output': 'def logical_raid_levels(self):\\n        \"\"\"Gets the raid level for each logical volume\\n\\n        :returns the set of list of raid levels configured\\n        \"\"\"\\n        lg_raid_lvls = set()\\n        for member in self.get_members():\\n            lg_raid_lvls.update(member.logical_drives.logical_raid_levels)\\n        return lg_raid_lvls</s>',\n",
       " 'input_ids': [2,\n",
       "  0,\n",
       "  19553,\n",
       "  14088,\n",
       "  33,\n",
       "  45,\n",
       "  4187,\n",
       "  93,\n",
       "  9072,\n",
       "  28,\n",
       "  22,\n",
       "  416,\n",
       "  12,\n",
       "  1317,\n",
       "  209,\n",
       "  41,\n",
       "  45,\n",
       "  329,\n",
       "  93,\n",
       "  2843,\n",
       "  28,\n",
       "  11,\n",
       "  8777,\n",
       "  950,\n",
       "  712,\n",
       "  22,\n",
       "  185,\n",
       "  93,\n",
       "  2478,\n",
       "  540,\n",
       "  1698,\n",
       "  28,\n",
       "  20,\n",
       "  798,\n",
       "  11,\n",
       "  49337,\n",
       "  5398,\n",
       "  122845,\n",
       "  16,\n",
       "  141,\n",
       "  28,\n",
       "  20,\n",
       "  7615,\n",
       "  556,\n",
       "  439,\n",
       "  26,\n",
       "  310,\n",
       "  3046,\n",
       "  1279,\n",
       "  736,\n",
       "  20,\n",
       "  108,\n",
       "  29,\n",
       "  59,\n",
       "  29,\n",
       "  7615,\n",
       "  556,\n",
       "  5639,\n",
       "  1807,\n",
       "  691,\n",
       "  11,\n",
       "  19629,\n",
       "  393,\n",
       "  603,\n",
       "  26,\n",
       "  132,\n",
       "  11,\n",
       "  49337,\n",
       "  4285,\n",
       "  16,\n",
       "  13,\n",
       "  3046,\n",
       "  46700,\n",
       "  8884,\n",
       "  21017,\n",
       "  31,\n",
       "  91,\n",
       "  28,\n",
       "  20,\n",
       "  7615,\n",
       "  556,\n",
       "  439,\n",
       "  26,\n",
       "  310,\n",
       "  3046,\n",
       "  1279,\n",
       "  736,\n",
       "  20,\n",
       "  108,\n",
       "  29,\n",
       "  59,\n",
       "  29,\n",
       "  7615,\n",
       "  556,\n",
       "  5639,\n",
       "  1807,\n",
       "  14,\n",
       "  91501,\n",
       "  46700,\n",
       "  8884,\n",
       "  121675,\n",
       "  28,\n",
       "  24,\n",
       "  890,\n",
       "  26,\n",
       "  907,\n",
       "  25,\n",
       "  454,\n",
       "  31472,\n",
       "  17,\n",
       "  91501,\n",
       "  46700,\n",
       "  8884,\n",
       "  121675,\n",
       "  11716,\n",
       "  110931,\n",
       "  73668,\n",
       "  114016,\n",
       "  73668,\n",
       "  9535,\n",
       "  8884,\n",
       "  21017,\n",
       "  21,\n",
       "  15,\n",
       "  91501,\n",
       "  46700,\n",
       "  8884,\n",
       "  121675,\n",
       "  28,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2],\n",
       " 'labels': [0,\n",
       "  19553,\n",
       "  14088,\n",
       "  33,\n",
       "  45,\n",
       "  4187,\n",
       "  93,\n",
       "  9072,\n",
       "  28,\n",
       "  22,\n",
       "  416,\n",
       "  12,\n",
       "  1317,\n",
       "  209,\n",
       "  41,\n",
       "  45,\n",
       "  329,\n",
       "  93,\n",
       "  2843,\n",
       "  28,\n",
       "  11,\n",
       "  8777,\n",
       "  950,\n",
       "  712,\n",
       "  22,\n",
       "  185,\n",
       "  93,\n",
       "  2478,\n",
       "  540,\n",
       "  1698,\n",
       "  28,\n",
       "  20,\n",
       "  798,\n",
       "  11,\n",
       "  49337,\n",
       "  5398,\n",
       "  122845,\n",
       "  16,\n",
       "  141,\n",
       "  28,\n",
       "  20,\n",
       "  7615,\n",
       "  556,\n",
       "  439,\n",
       "  26,\n",
       "  310,\n",
       "  3046,\n",
       "  1279,\n",
       "  736,\n",
       "  20,\n",
       "  108,\n",
       "  29,\n",
       "  59,\n",
       "  29,\n",
       "  7615,\n",
       "  556,\n",
       "  5639,\n",
       "  1807,\n",
       "  691,\n",
       "  11,\n",
       "  19629,\n",
       "  393,\n",
       "  603,\n",
       "  26,\n",
       "  132,\n",
       "  11,\n",
       "  49337,\n",
       "  4285,\n",
       "  16,\n",
       "  13,\n",
       "  3046,\n",
       "  46700,\n",
       "  8884,\n",
       "  21017,\n",
       "  31,\n",
       "  91,\n",
       "  28,\n",
       "  20,\n",
       "  7615,\n",
       "  556,\n",
       "  439,\n",
       "  26,\n",
       "  310,\n",
       "  3046,\n",
       "  1279,\n",
       "  736,\n",
       "  20,\n",
       "  108,\n",
       "  29,\n",
       "  59,\n",
       "  29,\n",
       "  7615,\n",
       "  556,\n",
       "  5639,\n",
       "  1807,\n",
       "  14,\n",
       "  91501,\n",
       "  46700,\n",
       "  8884,\n",
       "  121675,\n",
       "  28,\n",
       "  24,\n",
       "  890,\n",
       "  26,\n",
       "  907,\n",
       "  25,\n",
       "  454,\n",
       "  31472,\n",
       "  17,\n",
       "  91501,\n",
       "  46700,\n",
       "  8884,\n",
       "  121675,\n",
       "  11716,\n",
       "  110931,\n",
       "  73668,\n",
       "  114016,\n",
       "  73668,\n",
       "  9535,\n",
       "  8884,\n",
       "  21017,\n",
       "  21,\n",
       "  15,\n",
       "  91501,\n",
       "  46700,\n",
       "  8884,\n",
       "  121675,\n",
       "  28,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5a2a028-98bd-4e8b-afdf-c59d6f86f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91a4e3cc-502a-4e92-8b5c-ce4f7310a774",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 2\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(\n\u001b[0;32m      3\u001b[0m     trained_dataset,\n\u001b[0;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m      5\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mdefault_data_collator, \u001b[38;5;66;03m# we don't need any special collator 😎\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m eval_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m      8\u001b[0m     eval_dataset,\n\u001b[0;32m      9\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     10\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mdefault_data_collator,\n\u001b[0;32m     11\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "train_dataloader = DataLoader(\n",
    "    trained_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=default_data_collator, # we don't need any special collator 😎\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=default_data_collator,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33d9a90f-8133-469f-8434-8922c548abc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input_ids', 'labels']),\n",
       " tensor([    2,     0, 19553, 14088,    33,    45,  4187,    93,  9072,    28,\n",
       "            22,   416,    12,  1317,   209,    41,    45,   329,    93,  2843,\n",
       "            28,    11,  8777,   950,   712]),\n",
       " tensor([    0, 19553, 14088,    33,    45,  4187,    93,  9072,    28,    22,\n",
       "           416,    12,  1317,   209,    41,    45,   329,    93,  2843,    28,\n",
       "            11,  8777,   950,   712,    22]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = next(iter(train_dataloader))\n",
    "b.keys(), b[\"input_ids\"][0][:25], b[\"labels\"][0][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58e70d3c-72b2-41c9-90f8-e81d20e561a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Function to clear GPU memory\n",
    "def clear_gpu_memory():\n",
    "    # Delete model and tensors if they are defined\n",
    "    global model, inputs, input_ids\n",
    "    if 'model' in globals():\n",
    "        del model\n",
    "    if 'inputs' in globals():\n",
    "        del inputs\n",
    "    if 'input_ids' in globals():\n",
    "        del input_ids\n",
    "\n",
    "    # Clear PyTorch cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Force Python's garbage collector to run\n",
    "    gc.collect()\n",
    "\n",
    "# Call the function to clear GPU memory\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3021acf-c18c-4073-97b1-ac031e93a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "gradient_accumulation_steps = 32 // batch_size\n",
    "\n",
    "n_freeze = 24 # you can play with this parameter\n",
    "\n",
    "name_config = SimpleNamespace(\n",
    "    model_id=model_name,\n",
    "    dataset_name=\"code_search_net\",\n",
    "    precision=\"bf16\",  # faster and better than fp16, requires new GPUs\n",
    "    n_freeze=n_freeze,  # How many layers we don't train, LLama 7B has 32.\n",
    "    lr=2e-4,\n",
    "    n_eval_samples=10, # How many samples to generate on validation\n",
    "    max_seq_len=context_length, # Length of the sequences to pack\n",
    "    epochs=1,  # we do 1 pasess over the dataset.\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,  # evey how many iterations we update the gradients, simulates larger batch sizes\n",
    "    batch_size=batch_size,  # what my GPU can handle, depends on how many layers are we training  \n",
    "    log_model=False,  # upload the model to W&B?\n",
    "    mom=0.9, # optim param\n",
    "    gradient_checkpointing = True,  # saves even more memory\n",
    "    freeze_embed = False,  # why train this? let's keep them frozen ❄️\n",
    ")\n",
    "\n",
    "\n",
    "name_config.total_train_steps = name_config.epochs * len(train_dataloader) // name_config.gradient_accumulation_steps\n",
    "name_config.eval_every = name_config.total_train_steps//10. # we evaluate every 1/10th of the total train steps.\n",
    "\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "gen_config = GenerationConfig.from_pretrained(name_config.model_id)\n",
    "test_config = SimpleNamespace(\n",
    "    max_new_tokens=256,\n",
    "    gen_config=gen_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4bbbb8bd-a331-4a7e-aa88-7ea07ad0041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig , BitsAndBytesConfig , AutoModelForCausalLM\n",
    "import torch\n",
    "#bnb_config = BitsAndBytesConfig(\n",
    "#    load_in_4bit= True,\n",
    "#    bnb_4bit_quant_type= \"nf4\",\n",
    "#    bnb_4bit_compute_dtype= torch.float16,\n",
    "#    bnb_4bit_use_double_quant= False,\n",
    "#)\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    vocab_size=len(old_tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a40eaa98-ea79-4c60-a888-22852620b96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84963e4f4a140f2aa4be022c6d866f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    config = config,\n",
    "    device_map={\"\": 0},\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abb0dd72-7da1-4d17-849b-04519ab873b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(128482, 4096)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66aa7e26-0905-4d26-8daa-968756dd4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from huggingface_hub import notebook_login\n",
    "\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a428fabf-c6c0-4ccf-9910-9f2e1c63f836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mryuinw123\u001b[0m (\u001b[33mllm-courseville\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ryu/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"e52be3b876f1591b2e7c14126ecef4387c68d4aa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b47bb86-d763-46de-8f6c-f95d58129b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight\n"
     ]
    }
   ],
   "source": [
    "# freeze layers (disable gradients)\n",
    "for param in model.parameters(): param.requires_grad = False\n",
    "for param in model.lm_head.parameters(): param.requires_grad = True\n",
    "for param in model.model.layers[n_freeze:].parameters(): param.requires_grad = True\n",
    "for name, param in model.named_parameters():\n",
    "    if (name == \"model.embed_tokens.weight\"):\n",
    "        print(name)\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7769d40d-73c4-4074-886c-f47359a6c755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0d078db-2045-41eb-9987-2eb71db2a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=name_config.lr, betas=(0.9,0.99), eps=1e-5)\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optim,\n",
    "    num_training_steps=name_config.total_train_steps,\n",
    "    num_warmup_steps=name_config.total_train_steps // 10,\n",
    ")\n",
    "\n",
    "\n",
    "def loss_fn(x, y):\n",
    "    \"A Flat CrossEntropy\" \n",
    "    return torch.nn.functional.cross_entropy(x.view(-1, x.shape[-1]), y.view(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1a9b0df-96e1-4762-9f2f-4f32353f4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate(prompt, max_new_tokens=100, gen_config=gen_config):\n",
    "    with torch.inference_mode():\n",
    "        tokenized_prompt = tokenizer(prompt, return_tensors='pt')['input_ids'].cuda()\n",
    "        output = model.generate(tokenized_prompt, \n",
    "                            max_new_tokens=max_new_tokens, \n",
    "                            generation_config=gen_config)\n",
    "    return tokenizer.decode(output[0][len(tokenized_prompt[0]):], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c174addc-4293-46a3-acc4-9016023a8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def prompt_table(examples, log=False, table_name=\"predictions\"):\n",
    "    table = wandb.Table(columns=[\"prompt\", \"generation\", \"concat\", \"output\", \"max_new_tokens\", \"temperature\", \"top_p\"])\n",
    "    for example in tqdm(examples, leave=False):\n",
    "        prompt, gpt4_output = example[\"input\"], example[\"output\"]\n",
    "        out = generate(prompt, test_config.max_new_tokens, test_config.gen_config)\n",
    "        table.add_data(prompt, out, prompt+out, gpt4_output, test_config.max_new_tokens, test_config.gen_config.temperature, test_config.gen_config.top_p)\n",
    "    if log:\n",
    "        wandb.log({table_name:table})\n",
    "    return table\n",
    "\n",
    "def to_gpu(tensor_dict):\n",
    "    return {k: v.to('cuda') for k, v in tensor_dict.items()}\n",
    "\n",
    "class Accuracy:\n",
    "    \"A simple Accuracy function compatible with HF models\"\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.tp = 0.\n",
    "    def update(self, logits, labels):\n",
    "        logits, labels = logits.argmax(dim=-1).view(-1).cpu(), labels.view(-1).cpu()\n",
    "        tp = (logits == labels).sum()\n",
    "        self.count += len(logits)\n",
    "        self.tp += tp\n",
    "        return tp / len(logits)\n",
    "    def compute(self):\n",
    "        return self.tp / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46a9d74e-ac1e-456f-b68b-cecbb3192c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate():\n",
    "    model.eval();\n",
    "    eval_acc = Accuracy()\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch = to_gpu(batch)\n",
    "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            out = model(**batch)\n",
    "            loss = loss_fn(out.logits, batch[\"labels\"])  # you could use out.loss and not shift the dataset\n",
    "        eval_acc.update(out.logits, batch[\"labels\"])\n",
    "    # we log results at the end\n",
    "    wandb.log({\"eval_loss\": loss.item(),\n",
    "               \"eval_accuracy\": eval_acc.compute()})\n",
    "    prompt_table(eval_dataset[:name_config.n_eval_samples], log=True)\n",
    "    model.train();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78951c6a-50f5-4a1e-84ea-82521ee1df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def save_model(model, model_name, models_folder=\"models\", log=False):\n",
    "    \"\"\"Save the model to wandb as an artifact\n",
    "    Args:\n",
    "        model (nn.Module): Model to save.\n",
    "        model_name (str): Name of the model.\n",
    "        models_folder (str, optional): Folder to save the model. Defaults to \"models\".\n",
    "    \"\"\"\n",
    "    model_name = f\"{wandb.run.id}_{model_name}\"\n",
    "    file_name = Path(f\"{models_folder}/{model_name}\")\n",
    "    file_name.parent.mkdir(parents=True, exist_ok=True)\n",
    "    model.save_pretrained(file_name, safe_serialization=True)\n",
    "    # save tokenizer for easy inference\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model.name_or_path)\n",
    "    tokenizer.save_pretrained(model_name)\n",
    "    if log:\n",
    "        at = wandb.Artifact(model_name, type=\"model\")\n",
    "        at.add_dir(file_name)\n",
    "        wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03ec9883-27dd-404f-a7f6-5728978d2450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ryu\\Desktop\\llm\\finetunellm-code\\wandb\\run-20231119_143406-y9nn2npu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/llm-courseville/wangchanlgm-code/runs/y9nn2npu' target=\"_blank\">splendid-resonance-17</a></strong> to <a href='https://wandb.ai/llm-courseville/wangchanlgm-code' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/llm-courseville/wangchanlgm-code' target=\"_blank\">https://wandb.ai/llm-courseville/wangchanlgm-code</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/llm-courseville/wangchanlgm-code/runs/y9nn2npu' target=\"_blank\">https://wandb.ai/llm-courseville/wangchanlgm-code/runs/y9nn2npu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/llm-courseville/wangchanlgm-code/runs/y9nn2npu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2c701c118d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"wangchanlgm-code\", # the project I am working on\n",
    "           tags=[\"baseline\"],\n",
    "           config=name_config) # the Hyperparameters I want to keep track of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2596bb07-fb63-49ba-b217-42e550374256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59afb9f3df634337af5898673471e882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28fbaf33-ca74-428a-974e-93629dfdf176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a323879f524e5283855fa1d2f4e78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38a2ce33a884c5081e2a7cce8947aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4846343f915c465e991e31767b2c278f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4af869632684696870577bfc5879b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5179dc5bd1d34af49f4ef5c1595bee68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b78b112407411c996fd2b3bf7957a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a7a4bcf95644ad83ab7838ca7fc439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80b951b881b423bad3ce337caa9ca31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8637b9130248498bbdc74c7720392b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51fc66b6bc0422c96ae8425d794e448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d291fb50bbf0426a808d5a163c31fd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb7505c58a849938da290b8949c67ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef73eee05634fbba1700793352df35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.723 MB of 0.729 MB uploaded\\r'), FloatProgress(value=0.992196922722718, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_accuracy</td><td>▁███████████</td></tr><tr><td>eval_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▂▃▅▆██████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆▆▇▆█▅▇▄▆▅▇▄▅█▅▆▆▇▇▆█▆▆▆▇▇▆▇▆▆▇▇▆▇▇▄▆▆</td></tr><tr><td>train_loss</td><td>█▃▃▃▂▃▁▅▃▇▄▄▂▆▅▂▅▄▃▃▂▄▁▃▃▅▂▂▅▂▄▄▂▂▃▂▃▆▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_accuracy</td><td>0.72432</td></tr><tr><td>eval_loss</td><td>4.64692</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>train_accuracy</td><td>0.60392</td></tr><tr><td>train_loss</td><td>3.4996</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">splendid-resonance-17</strong> at: <a href='https://wandb.ai/llm-courseville/wangchanlgm-code/runs/y9nn2npu' target=\"_blank\">https://wandb.ai/llm-courseville/wangchanlgm-code/runs/y9nn2npu</a><br/>Synced 4 W&B file(s), 12 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231119_143406-y9nn2npu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = Accuracy()\n",
    "model.train()\n",
    "train_step = 0\n",
    "for epoch in tqdm(range(name_config.epochs)):\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = to_gpu(batch)\n",
    "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            out = model(**batch)\n",
    "            loss = loss_fn(out.logits, batch[\"labels\"]) / name_config.gradient_accumulation_steps  # you could use out.loss and not shift the dataset  \n",
    "            loss.backward()\n",
    "\n",
    "        if step % name_config.gradient_accumulation_steps == 0:\n",
    "            # Log the metrics to W&B\n",
    "            wandb.log({\n",
    "                \"train_loss\": loss.item() * name_config.gradient_accumulation_steps,\n",
    "                \"train_accuracy\": acc.update(out.logits, batch[\"labels\"]),\n",
    "                \"lr\": scheduler.get_last_lr()[0]\n",
    "            })\n",
    "            \n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            train_step += 1\n",
    "\n",
    "            # Perform validation every 1/10th of the total_train_steps\n",
    "            if train_step % name_config.eval_every == 0 or train_step % (name_config.total_train_steps - 1) == 0:\n",
    "                validate()\n",
    "\n",
    "\n",
    "# we save the model checkpoint at the end\n",
    "save_model(model, model_name=name_config.model_id.replace(\"/\", \"_\"), models_folder=\"models/\", log=name_config.log_model)\n",
    "    \n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac5e0f01-dcf1-4eb1-98c7-b870ca43bb16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m new_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwangchanglm-finetune\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpush_to_hub(new_model)\n\u001b[0;32m      3\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpush_to_hub(new_model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "new_model = \"ryuinw123/wangchanglm-finetune\"\n",
    "model.push_to_hub(new_model)\n",
    "tokenizer.push_to_hub(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "323a3314-69a6-4ace-a7dc-e6e48eb2a1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\ryu\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "!huggingface-cli login --token \"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\"\n",
    "\n",
    "new_model = \"ryuinw123/wangchanglm-finetune\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c4e4a44-ed08-41d6-8c94-b88e8919cb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab323a383534d6f93a1424adca8f1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig , BitsAndBytesConfig , AutoModelForCausalLM\n",
    "import torch\n",
    "#bnb_config = BitsAndBytesConfig(\n",
    "#    load_in_4bit= True,\n",
    "#    bnb_4bit_quant_type= \"nf4\",\n",
    "#    bnb_4bit_compute_dtype= torch.float16,\n",
    "#    bnb_4bit_use_double_quant= False,\n",
    "#)\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    new_model,\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=256,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffbe1d19-63b8-4096-ae6c-31b250d9db3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25698d5636842dead2563c44bf7ea31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/40.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc130a7fdf9a4f7a9779991fe5b6d175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c22d403599f4ff5b33b91a6744939a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe6f273913d46f19f993d400aea8df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8387de8b01474aa06e6a0560e695a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/4.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafd381cbbb84271a45ce109d15de795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e92f16bebc440882a868f627d986b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    new_model,\n",
    "    config = config,\n",
    "    device_map={\"\": 0},\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d169dc-6253-4f04-b63b-aa3bf684f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"<s>Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "            Write a response that appropriately completes the request.\\n\\n\n",
    "            ### Instruction:\\n I want to write code to print \"1 2 3\" If coding use python for it \\n\\n \\n\\n### Response:\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427e761-0fb3-407f-94aa-415d11c9054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(data , )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
